# Cluster Data Standards and Output Structure

## Problem Statement

**Current Issue**: Experiments on the cluster generate inconsistent output structures:
- Single-degree experiments (`degree_range = 4:4`) → Cannot visualize convergence trends
- Multiple JSON schema versions in use
- Inconsistent field names across experiment types
- No standard way to determine if an experiment has sufficient data for analysis

**Impact**:
- Cannot generate meaningful convergence plots (need multiple degrees)
- Post-processing scripts must handle multiple schema versions
- Visualization tools fail on single-degree experiments
- Manual intervention required to identify "complete" experiments

## Required Data Structure Standards

### 1. Minimum Degree Coverage

**STANDARD**: All experiments MUST test **at least 3 degrees** for convergence analysis.

```julia
# ❌ WRONG - Single degree
degree_range = 4:4

# ✅ CORRECT - Minimum 3 degrees
degree_range = 4:6      # Small/fast test
degree_range = 4:8      # Standard test
degree_range = 4:12     # Comprehensive test
```

**Rationale**:
- Single degree: No convergence trend
- Two degrees: Insufficient for trend analysis
- Three+ degrees: Minimum for meaningful convergence visualization

### 2. Unified JSON Schema (v1.1.0)

**STANDARD**: All experiments MUST use Schema v1.1.0 output format.

```json
{
  "schema_version": "1.1.0",
  "experiment_type": "string (e.g., '4dlv_parameter_recovery')",
  "experiment_id": "string (DrWatson-generated or custom)",
  "timestamp": "YYYYMMDD_HHMMSS",

  "params_dict": {
    "GN": "int (samples per dimension)",
    "degree_range": "array of ints tested",
    "domain_size_param": "float (domain bounds parameter)",
    "max_time": "float (time limit in seconds)",
    "...": "additional experiment-specific parameters"
  },

  "system_info": {
    "dimension": "int",
    "system_type": "string (e.g., 'lotka_volterra_4d_parameter_recovery')",
    "true_parameters": "array (only for parameter recovery experiments)",
    "search_domain_center": "array",
    "search_domain_size": "float",
    "...": "additional system description fields"
  },

  "results_summary": {
    "degree_4": {
      "status": "success|failed",
      "l2_approx_error": "float",
      "condition_number": "float",
      "critical_points": "int (raw count before filtering)",
      "critical_points_refined": "int (after refinement and filtering)",
      "computation_time": "float (seconds)",
      "...": "timing breakdown and other metrics"
    },
    "degree_5": { "..." },
    "...": "one entry per degree tested"
  },

  "total_time": "float (total experiment time)",
  "degrees_processed": "int (number of degrees completed)",
  "success_rate": "float (fraction of degrees that succeeded)"
}
```

**Key Requirements**:
1. `schema_version` field MUST be present
2. `params_dict.degree_range` MUST be an array with length >= 3
3. `results_summary` MUST have entries for each degree in `degree_range`
4. For parameter recovery: `system_info.true_parameters` MUST be present

### 3. Critical Points Data

**STANDARD**: When critical points are found, they MUST be saved to CSV.

**File naming**: `critical_points_deg_<degree>.csv`

**Required columns** (parameter recovery experiments):
```csv
theta1_raw,theta2_raw,theta3_raw,theta4_raw,theta1,theta2,theta3,theta4,objective_raw,objective,recovery_error,refinement_improvement,l2_approx_error
```

**Current Issue**: CSV files only saved when `n_valid > 0` (points in domain after refinement).
This excludes experiments where all refined points fall outside domain bounds.

**Proposed Fix**: Always save refined critical points to CSV, even if outside domain.
Add `in_domain` boolean column to indicate whether each point passed domain filter.

### 4. Output Directory Structure

**STANDARD**: Each experiment creates a directory with DrWatson-style naming:

```
hpc_results/
  <experiment_name>_<params>_<timestamp>/
    ├── results_summary.json          # REQUIRED - main results (Schema v1.1.0)
    ├── critical_points_deg_4.csv     # REQUIRED if critical points found
    ├── critical_points_deg_5.csv     # One per degree in degree_range
    ├── critical_points_deg_6.csv
    ├── ...
    ├── true_trajectory.csv           # OPTIONAL - for parameter recovery
    ├── convergence_analysis.png      # GENERATED by post-processing
    └── experiment.log                # OPTIONAL - stdout/stderr capture
```

## Implementation Requirements

### For Experiment Scripts

**1. Update Default Degree Ranges**

```julia
# Examples/4DLV/parameter_recovery_experiment.jl
params = parse_experiment_args(ARGS, defaults=(
    GN = 5,
    degree_range = 4:6,  # CHANGED FROM 4:4 to minimum 3 degrees
    domain_size_param = 0.3,
    max_time = 60.0
))
```

**2. Always Save Critical Points**

```julia
# Save ALL refined critical points, not just those in domain
if refinement_stats.converged > 0
    df_all_critical = DataFrame(
        # ... all critical points including those outside domain
        in_domain = [pt in valid_critical_points for pt in refined_points]
    )
    CSV.write("$output_dir/critical_points_deg_$degree.csv", df_all_critical)
end
```

**3. Schema Version Field**

```julia
# Add to all JSON output
results_dict["schema_version"] = "1.1.0"
```

### For Launcher Scripts

**1. Update Degree Ranges**

```bash
# scripts/launch_4dlv_param_recovery.sh

# Phase 1: Small quick tests (now 3 degrees minimum)
launch_experiment 5 4 6 0.3    # CHANGED FROM 4-4

# Phase 2: Medium tests
launch_experiment 6 4 6 0.3    # CHANGED FROM 4-5
launch_experiment 7 4 6 0.3

# Phase 3: Larger tests
launch_experiment 8 4 7 0.3
launch_experiment 10 4 8 0.3
```

### For Visualization Scripts

**1. Validation Check**

```julia
# scripts/analysis/plot_convergence_simple.jl

function validate_experiment_for_plotting(data::Dict)
    degree_range = get(data, "params_dict", Dict())["degree_range"]

    if length(degree_range) < 3
        error("Insufficient degrees for convergence plot. Found $(length(degree_range)), need >= 3.")
    end

    return true
end
```

**2. Interactive Display Support**

Currently generating static PNG files. For interactive visualization:
- Use GLMakie for interactive display
- Support both PNG export and interactive window
- Add command-line flag: `--interactive` vs `--static`

## Migration Path

### Phase 1: Update Core Experiments (Immediate)
- [x] Document standards (this file)
- [ ] Update `parameter_recovery_experiment.jl` default degrees: 4:4 → 4:6
- [ ] Update CSV saving to include all critical points with `in_domain` column
- [ ] Add schema version validation to all experiment scripts

### Phase 2: Update Infrastructure (This Week)
- [ ] Update launcher scripts with new degree ranges
- [ ] Add validation to plotting scripts (reject single-degree experiments)
- [ ] Create migration script to add schema version to legacy experiments

### Phase 3: Documentation & Testing (Next Week)
- [ ] Update HPC execution guide with standardized workflows
- [ ] Create example "good" vs "bad" experiment outputs
- [ ] Add automated tests for schema compliance

## Testing the Standards

**Test Experiment**: Run parameter recovery with new standards:

```bash
# From local machine
ssh scholten@r04n02
cd /home/scholten/globtimcore

# Test with standardized parameters
julia --project=. Examples/4DLV/parameter_recovery_experiment.jl \
    --GN=5 \
    --degrees=4:6 \
    --domain=0.3

# Verify output
ls -la hpc_results/<experiment_dir>/
# Should see:
# - results_summary.json with schema_version=1.1.0
# - degree_range=[4,5,6] in params_dict
# - critical_points_deg_4.csv (if any points found)
# - critical_points_deg_5.csv
# - critical_points_deg_6.csv
```

**Validation**: Convergence plots should display properly:

```bash
# From local machine
julia --project=. scripts/analysis/plot_convergence_simple.jl \
    hpc_results/<experiment_dir>/

# Should generate 4-panel plot with convergence trends
```

## Open Questions

1. **Interactive vs Static Plots**: ✅ **RESOLVED (Oct 1, 2025)**
   - **Implemented**: Interactive GLMakie display by default with `--static` flag for PNG
   - Usage: `julia plot_convergence_simple.jl <dir>` → Interactive window
   - Usage: `julia plot_convergence_simple.jl --static <dir>` → PNG export
   - Features: Zoom, pan, interactive exploration in GLMakie mode

2. **Critical Points Outside Domain**: Save all or only those in domain?
   - Current: Only in-domain points saved
   - Proposed: Save all with `in_domain` boolean column

3. **Legacy Experiments**: Migrate to v1.1.0 or keep separate?
   - Proposed: Keep legacy, add schema version to allow multi-version support

4. **Minimum Degree Range**: Is 3 sufficient or should we require more?
   - Current proposal: 3 minimum
   - Alternative: 4-5 for better trend fitting

## References

- Schema v1.1.0 introduced in: Issue #109 (Critical Point Refinement)
- DrWatson integration: `using DrWatson; @dict; savename()`
- Current post-processing: `scripts/analysis/collect_cluster_experiments.jl`
- Current visualization: `scripts/analysis/plot_convergence_simple.jl`
