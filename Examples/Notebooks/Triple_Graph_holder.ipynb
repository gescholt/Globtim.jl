{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we define new structure which captures the input parameters specific to each problem in one place (`scale_factor`).\n",
    "We need to define a range on `d` that is also function dependent (that we could adjust by hand). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate three graphs: \n",
    "- Histogram of Number of `loc_min` points were found, (so outputs of the Optim routine) and what percentage of them is within a small distance of a critical point of the approximant. As a function of the degree `d` of the approximant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using Revise \n",
    "Pkg.activate(\"../../.\")\n",
    "using Globtim\n",
    "using DynamicPolynomials, DataFrames\n",
    "using ProgressLogging\n",
    "using Optim\n",
    "using CairoMakie\n",
    "CairoMakie.activate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can a function export \"Optional attributes\" like just some constants or its optimal domain of definition? --> works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_function_params(\"HolderTable\")\n",
    "TR = test_input(HolderTable;\n",
    "    dim=params.dim,\n",
    "    center=params.center,\n",
    "    GN=params.num_samples,\n",
    "    sample_range=params.sample_range,\n",
    "    tolerance=params.tolerance)\n",
    "\n",
    "@polyvar(x[1:TR.dim]); # Define polynomial ring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_min, d_max = 4, 30\n",
    "TD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_degrees(TR, x, d_min, d_max, step=1, tol_dist=TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_results = analyze_degrees(TR, x, d_min, d_max, results, tol_dist=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plot_discrete_l2(results, d_min, d_max, 1)\n",
    "# save(\"discrete_l2.pdf\", fig_1)\n",
    "display(fig_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_2 = capture_histogram(results, d_min, d_max, 1, tol_dist=TD, show_legend = false)\n",
    "# save(\"histogram.pdf\", fig_2)\n",
    "display(fig_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3 = plot_convergence_analysis(results, d_min, d_max, 1)\n",
    "# save(\"convergence_analysis.pdf\", fig_3)\n",
    "display(fig_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT = results[18]\n",
    "df_t = RT.df\n",
    "df_m = RT.df_min;\n",
    "# pol_cheb = Constructor(TR, 18, basis=:chebyshev)\n",
    "sort!(df_t, :z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the mast here may not be that useful. We care of the minimal distance separating the optimized points from the critical points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_mask = points_in_hypercube(df_t, TR)\n",
    "values_mask = points_in_range(df_t, TR, 18.)\n",
    "df_minimizers = df_t[values_mask .& inside_mask, :] # has both `x` (raw) and `y` (optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CairoMakie.activate!\n",
    "fig_1 = cairo_plot_polyapprox_levelset(pol_cheb, TR, df_t, df_m, show_captured=false)\n",
    "# fig_1_p = cairo_plot_polyapprox_levelset(pol_cheb, TR, df_minimizers, df_m, show_captured=false)\n",
    "# save(\"polyapprox_levelset_just_crit.pdf\", fig_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = analyze_converged_points(df_t, TR, results, d_min, d_max, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_5 = plot_distance_statistics(stats)\n",
    "# save(\"distance_to_minimizer.pdf\", fig_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_distance_statistics(stats::Dict{String,Any}; show_legend::Bool=true)\n",
    "    fig = Figure(size=(600, 400))\n",
    "\n",
    "    ax = Axis(fig[1, 1],\n",
    "        xlabel=\"Degree\")\n",
    "\n",
    "    # Plot maximum and average distances\n",
    "    degrees = stats[\"degrees\"]\n",
    "    scatterlines!(ax, degrees, stats[\"max_distances\"],\n",
    "        label=\"Maximum\",\n",
    "        color=:red)\n",
    "    scatterlines!(ax, degrees, stats[\"avg_distances\"],\n",
    "        label=\"Average\",\n",
    "        color=:blue)\n",
    "\n",
    "    if show_legend\n",
    "        axislegend(ax)\n",
    "    end\n",
    "\n",
    "    return fig\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function analyze_converged_points(\n",
    "    df_filtered::DataFrame,\n",
    "    TR::test_input,\n",
    "    results::Dict{Int,NamedTuple{(:df, :df_min, :convergence_stats, :discrete_l2),\n",
    "        Tuple{DataFrame,DataFrame,NamedTuple,Float64}}},\n",
    "    start_degree::Int,\n",
    "    end_degree::Int,\n",
    "    step::Int=1)\n",
    "\n",
    "    degrees = start_degree:step:end_degree\n",
    "    n_dims = count(col -> startswith(string(col), \"x\"), names(df_filtered))\n",
    "\n",
    "    # Filter for converged points first\n",
    "    df_converged = df_filtered[df_filtered.converged, :]\n",
    "\n",
    "    # Filter for points where y is in domain and not NaN\n",
    "    valid_points = trues(nrow(df_converged))\n",
    "    for i in 1:nrow(df_converged)\n",
    "        # Check if y coordinates are NaN\n",
    "        y_coords = [df_converged[i, Symbol(\"y$j\")] for j in 1:n_dims]\n",
    "        if any(isnan.(y_coords))\n",
    "            valid_points[i] = false\n",
    "            continue\n",
    "        end\n",
    "\n",
    "        # Check if y coordinates are in domain\n",
    "        for j in 1:n_dims\n",
    "            if abs(df_converged[i, Symbol(\"y$j\")] - TR.center[j]) > TR.sample_range\n",
    "                valid_points[i] = false\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    df_valid = df_converged[valid_points, :]\n",
    "    n_valid_points = nrow(df_valid)\n",
    "\n",
    "    # Initialize distance matrix\n",
    "    point_distances = zeros(Float64, n_valid_points, length(degrees))\n",
    "\n",
    "    # Calculate distances\n",
    "    for (i, row) in enumerate(eachrow(df_valid))\n",
    "        y_coords = [row[Symbol(\"y$j\")] for j in 1:n_dims]\n",
    "\n",
    "        for (d_idx, d) in enumerate(degrees)\n",
    "            raw_points = results[d].df\n",
    "            min_dist = Inf\n",
    "\n",
    "            for raw_row in eachrow(raw_points)\n",
    "                point = [raw_row[Symbol(\"x$j\")] for j in 1:n_dims]\n",
    "                dist = norm(y_coords - point)\n",
    "                min_dist = min(min_dist, dist)\n",
    "            end\n",
    "            point_distances[i, d_idx] = min_dist\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Calculate statistics\n",
    "    stats = Dict{String,Any}()\n",
    "\n",
    "    # Per-degree statistics\n",
    "    stats[\"max_distances\"] = [maximum(point_distances[:, i]) for i in 1:length(degrees)]\n",
    "    stats[\"min_distances\"] = [minimum(point_distances[:, i]) for i in 1:length(degrees)]\n",
    "    stats[\"avg_distances\"] = [mean(point_distances[:, i]) for i in 1:length(degrees)]\n",
    "\n",
    "    # Overall statistics\n",
    "    stats[\"overall_max\"] = maximum(stats[\"max_distances\"])\n",
    "    stats[\"overall_min\"] = minimum(stats[\"min_distances\"])\n",
    "    stats[\"overall_avg\"] = mean(stats[\"avg_distances\"])\n",
    "\n",
    "    # Additional metadata\n",
    "    stats[\"n_total_points\"] = nrow(df_filtered)\n",
    "    stats[\"n_converged\"] = nrow(df_converged)\n",
    "    stats[\"n_valid\"] = n_valid_points\n",
    "    stats[\"degrees\"] = collect(degrees)\n",
    "\n",
    "    return stats\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
