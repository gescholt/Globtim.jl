{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is a small parcel to work on, with a nice contourplot with critical points and minima found after initiating local method and then a 3d plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Globtim\n",
    "include(\"../src/lib_func.jl\")\n",
    "\n",
    "# Constants and Parameters\n",
    "d = 8 # Initial Degree \n",
    "const n, a, b = 2, 10, 1 \n",
    "const scale_factor = a / b       # Scaling factor appears in `main_computation`, maybe it should be a parameter.\n",
    "const delta, alpha = .9 , 8 / 10  # Sampling parameters\n",
    "const tol_l2 = 3e-2             # Define the tolerance for the L2-norm\n",
    "\n",
    "f = HolderTable # Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to also return the number of samples used to generate the sample set. It is annoying that the error goes up while the degree has increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while true # Potential infinite loop\n",
    "    global poly_approx = MainGenerate(f, 2, d, delta, alpha, scale_factor, 0.2) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx.nrm < tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx.nrm)\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx.nrm)\n",
    "        println(\"Number of samples: \", poly_approx.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming x is already defined as @polyvar x[1:2]\n",
    "loc = \"inputs.ms\"\n",
    "# File path of the output file\n",
    "file_path_output = \"outputs.ms\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now expand the approximant computed in the tensorized Chebyshev basis into standard monomial basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DynamicPolynomials, DataFrames\n",
    "ap = main_nd(n, d, poly_approx.coeffs) \n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "# Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "names = [x[i].name for i in 1:length(x)]\n",
    "open(loc, \"w\") do file\n",
    "    println(file, join(names, \", \"))\n",
    "    println(file, 0)\n",
    "end\n",
    "# Define the polynomial approximant \n",
    "PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "for i in 1:n\n",
    "    partial = differentiate(PolynomialApproximant, x[i])\n",
    "    partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "    open(loc, \"a\") do file\n",
    "        if i < n\n",
    "            println(file, string(partial_str, \",\"))\n",
    "        else\n",
    "            println(file, partial_str)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve with Msolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(`msolve -v 1 -f inputs.ms -o outputs.ms`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function average(X::Vector{Int})::Float64\n",
    "    return sum(X) / length(X)\n",
    "end\n",
    "\n",
    "# Process the file and get the points\n",
    "evaled = process_output_file(file_path_output)\n",
    "\n",
    "# Parse the points into correct format\n",
    "real_pts = []\n",
    "for pts in evaled\n",
    "    if typeof(pts)== Vector{Vector{Vector{BigInt}}}\n",
    "        X = parse_point(pts)\n",
    "    else \n",
    "        X = average.(pts) \n",
    "    end\n",
    "    push!(real_pts, Float64.(X))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort through the critical points, make sure they fall into the domain of definition. Make them into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# Colllect the critical points of the approximant \n",
    "h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "h_z = map(p -> f([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "df = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z= h_z) # Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PlotlyJS, Colors\n",
    "# Generate the grid and evaluate the function\n",
    "N = 60  # resolution of the grid\n",
    "x = range(-scale_factor, scale_factor, length=N)\n",
    "y = range(-scale_factor, scale_factor, length=N)\n",
    "z = [f([xi, yi]) for yi in y, xi in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = surface(x=x, y=y, z=z)\n",
    "# Had to switch the coordinates of the critical points to match the surface plot for some reason. \n",
    "crit_pts = scatter3d(x=df.y, y=df.x, z=df.z, mode=\"markers\", marker_size=5, name=\"Critical Points\")\n",
    "\n",
    "# Layout for the plot\n",
    "layout = Layout(title=\"3D Plot of Trefethen function\",\n",
    "    scene=attr(\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"y\",\n",
    "        zaxis_title=\"f(x, y)\"),\n",
    "        height=800\n",
    ")\n",
    "# Display the plot layout,\n",
    "plot([sf,  crit_pts], layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to run some Optimization on the points computed to try to refine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the collected entries \n",
    "using Optim, LinearAlgebra\n",
    "for i in 1:nrow(df)\n",
    "    println(\"Optimizing for point $i\")\n",
    "    x0 = [df.x[i], df.y[i]]\n",
    "    try\n",
    "        res = Optim.optimize(f, x0, LBFGS(), Optim.Options(show_trace=true))\n",
    "        minimizer = Optim.minimizer(res)\n",
    "        min_value = Optim.minimum(res)\n",
    "        steps = res.iterations\n",
    "        converged = Optim.converged(res)\n",
    "        distance = norm(x0 - minimizer)\n",
    "\n",
    "        println(summary(res))\n",
    "    catch e\n",
    "        println(\"Optimization failed for point $i with error: \", e)\n",
    "    end\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
