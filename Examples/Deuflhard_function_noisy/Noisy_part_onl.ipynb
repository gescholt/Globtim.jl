{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add A Random Noise \n",
    "\n",
    "For this example, we consider a Gaussian noise centered at $0$ of `std_dev = 5`= at each evaluation point of $f$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Globtim\n",
    "using DynamicPolynomials, DataFrames\n",
    "using PlotlyJS, Colors\n",
    "using Distributions\n",
    "\n",
    "include(\"../../src/lib_func.jl\")\n",
    "\n",
    "# Constants and Parameters\n",
    "d = 1 # Initial Degree \n",
    "const n, a, b = 2, 11, 10 \n",
    "const scale_factor = a / b       # Scaling factor appears in `main_computation`, maybe it should be a parameter.\n",
    "const delta, alpha = .5 , 1 / 10  # Sampling parameters # Delta used to be too big \n",
    "const tol_l2 = 1e-4            # Define the tolerance for the L2-norm\n",
    "const sample_scale = 1.0\n",
    "\n",
    "function noisy_Deuflhard(xx::Vector{Float64}; mean::Float64=0.0, stddev::Float64=5.0)::Float64\n",
    "    noise = rand(Normal(mean, stddev))\n",
    "    return Deuflhard(xx) + noise\n",
    "end\n",
    "\n",
    "f_noisy = noisy_Deuflhard\n",
    "d = 1\n",
    "noisy_tol_l2 = 2.6e-2        # Define the noise affected tolerance for the L2-norm\n",
    "alpha_noise = 0.20 # probability of discrete L2 norm not being accurate to the set tolerance.\n",
    "\n",
    "while true # Potential infinite loop\n",
    "    global poly_approx_noisy = MainGenerate(f_noisy, 2, d, delta, alpha_noise, scale_factor, sample_scale) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx_noisy.nrm < noisy_tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx_noisy.nrm)\n",
    "        println(\"Degree: $d\")\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx_noisy.nrm)\n",
    "        println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end\n",
    "# ==================================================================================================\n",
    "loc = \"inputs.ms\"\n",
    "# File path of the output file\n",
    "file_path_output = \"outputs.ms\";\n",
    "# ==================================================================================================\n",
    "ap = main_nd(n, d, poly_approx_noisy.coeffs)\n",
    "# ==================================================================================================\n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "# Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "names = [x[i].name for i in 1:length(x)]\n",
    "open(loc, \"w\") do file\n",
    "    println(file, join(names, \", \"))\n",
    "    println(file, 0)\n",
    "end\n",
    "# Define the polynomial approximant \n",
    "PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "for i in 1:n\n",
    "    partial = differentiate(PolynomialApproximant, x[i])\n",
    "    partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "    open(loc, \"a\") do file\n",
    "        if i < n\n",
    "            println(file, string(partial_str, \",\"))\n",
    "        else\n",
    "            println(file, partial_str)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "# ==================================================================================================\n",
    "run(`msolve -v 0 -f inputs.ms -o outputs.ms`)\n",
    "# ==================================================================================================\n",
    "evaled = process_output_file(file_path_output)  # Process the file and get the points\n",
    "\n",
    "real_pts = []\n",
    "for pts in evaled\n",
    "    if typeof(pts) == Vector{Vector{Vector{BigInt}}}\n",
    "        X = parse_point(pts) # Parse the points into correct format\n",
    "    else\n",
    "        X = average.(pts)\n",
    "    end\n",
    "    push!(real_pts, Float64.(X))\n",
    "end\n",
    "\n",
    "# ==================================================================================================\n",
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# Colllect the critical points of the approximant \n",
    "h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "\n",
    "# Here we should evaluate on the noiseless function to compare with previous results\n",
    "h_z = map(p -> Deuflhard([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "\n",
    "df_noisy = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z=h_z); # Create a DataFrame\n",
    "\n",
    "coords = poly_approx_noisy.scale_factor * poly_approx_noisy.grid\n",
    "z_coords = poly_approx_noisy.z\n",
    "\n",
    "# ==================================================================================================\n",
    "# Plot the 3D scatter plot if the dimensions are 2\n",
    "if size(coords)[2] == 2\n",
    "    scatter_trace = scatter3d(\n",
    "        x=coords[:, 1],\n",
    "        y=coords[:, 2],\n",
    "        z=z_coords,\n",
    "        mode=\"markers\",\n",
    "        marker=attr(\n",
    "            size=1,\n",
    "            color=z_coords,\n",
    "            colorscale=\"Viridis\"\n",
    "        ),\n",
    "        name=\"Sampled Noisy Data\"\n",
    "    )\n",
    "    # Had to switch the coordinates of the critical points to match the surface plot for some reason. \n",
    "    crit_pts_noisy = scatter3d(\n",
    "        x=df_noisy.y,\n",
    "        y=df_noisy.x,\n",
    "        z=df_noisy.z,\n",
    "        mode=\"markers\",\n",
    "        marker=attr(\n",
    "            size=8,\n",
    "            color=\"orange\"\n",
    "        ),\n",
    "        name=\"Critical Points\"\n",
    "    )\n",
    "\n",
    "    layout = Layout(\n",
    "        title=\"3D Scatter Plot of Sample Points\",\n",
    "        scene=attr(\n",
    "            xaxis=attr(title=\"X-axis\"),\n",
    "            yaxis=attr(title=\"Y-axis\"),\n",
    "            zaxis=attr(title=\"Z-axis\")),\n",
    "        height=800\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"L2 tolerance: $noisy_tol_l2\")\n",
    "println(\"Degree: $d\")\n",
    "println(\"current L2-norm: \", poly_approx_noisy.nrm)\n",
    "println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "plt = Plot([scatter_trace, crit_pts_noisy], layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We make the tolerance tighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_tol_l2 = 2.2e-2\n",
    "d = 1\n",
    "while true # Potential infinite loop\n",
    "    global poly_approx_noisy = MainGenerate(f_noisy, 2, d, delta, alpha_noise, scale_factor, sample_scale) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx_noisy.nrm < noisy_tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx_noisy.nrm)\n",
    "        println(\"Degree: $d\")\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx_noisy.nrm)\n",
    "        println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end\n",
    "ap = main_nd(n, d, poly_approx_noisy.coeffs)\n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "names = [x[i].name for i in 1:length(x)]\n",
    "open(loc, \"w\") do file\n",
    "    println(file, join(names, \", \"))\n",
    "    println(file, 0)\n",
    "end\n",
    "PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "for i in 1:n\n",
    "    partial = differentiate(PolynomialApproximant, x[i])\n",
    "    partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "    open(loc, \"a\") do file\n",
    "        if i < n\n",
    "            println(file, string(partial_str, \",\"))\n",
    "        else\n",
    "            println(file, partial_str)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "run(`msolve -v 1 -f inputs.ms -o outputs.ms`)\n",
    "evaled = process_output_file(file_path_output)\n",
    "real_pts = []\n",
    "for pts in evaled\n",
    "    if typeof(pts) == Vector{Vector{Vector{BigInt}}}\n",
    "        X = parse_point(pts)\n",
    "    else\n",
    "        X = average.(pts)\n",
    "    end\n",
    "    push!(real_pts, Float64.(X))\n",
    "end\n",
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "h_z = map(p -> Deuflhard([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "df_5_noisy = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z=h_z); # Create a DataFrame\n",
    "\n",
    "## For Plots ##\n",
    "# Collect the Sample set and evaluations data and rescale it \n",
    "coords = poly_approx_noisy.scale_factor * poly_approx_noisy.grid\n",
    "z_coords = poly_approx_noisy.z\n",
    "\n",
    "# Plot the 3D scatter plot if the dimensions are 2\n",
    "scatter_trace = scatter3d(\n",
    "    x=coords[:, 1],\n",
    "    y=coords[:, 2],\n",
    "    z=z_coords,\n",
    "    mode=\"markers\",\n",
    "    marker=attr(\n",
    "        size=1,\n",
    "        color=z_coords,\n",
    "        colorscale=\"Viridis\"\n",
    "    ),\n",
    "    name=\"Sampled Noisy Data\"\n",
    ")\n",
    "\n",
    "crit_pts_5_noisy = scatter3d(\n",
    "    x=df_5_noisy.y,\n",
    "    y=df_5_noisy.x,\n",
    "    z=df_5_noisy.z,\n",
    "    mode=\"markers\",\n",
    "    marker=attr(\n",
    "        size=8,\n",
    "        color=\"orange\"\n",
    "    ),\n",
    "    name=\"Critical Points\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"L2 tolerance: $noisy_tol_l2\")\n",
    "println(\"Degree: $d\")\n",
    "println(\"current L2-norm: \", poly_approx_noisy.nrm)\n",
    "println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "plt = Plot([scatter_trace, crit_pts_5_noisy], layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
