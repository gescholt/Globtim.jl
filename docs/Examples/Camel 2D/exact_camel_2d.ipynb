{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is a small parcel to work on, with a nice contourplot with critical points and minima found after initiating local method and then a 3d plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Globtim\n",
    "include(\"../src/lib_func.jl\")\n",
    "\n",
    "# Constants and Parameters\n",
    "d = 8 # Initial Degree \n",
    "const n, a, b = 2, 5, 1 \n",
    "const scale_factor = a / b       # Scaling factor appears in `main_computation`, maybe it should be a parameter.\n",
    "const delta, alpha = .9 , 8 / 10  # Sampling parameters\n",
    "const tol_l2 = 3e-4             # Define the tolerance for the L2-norm\n",
    "\n",
    "f = camel # Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to also return the number of samples used to generate the sample set. It is annoying that the error goes up while the degree has increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while true # Potential infinite loop\n",
    "    global poly_approx = MainGenerate(f, 2, d, delta, alpha, scale_factor, 0.2) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx.nrm < tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx.nrm)\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx.nrm)\n",
    "        println(\"Number of samples: \", poly_approx.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming x is already defined as @polyvar x[1:2]\n",
    "loc = \"inputs.ms\"\n",
    "# File path of the output file\n",
    "file_path_output = \"outputs.ms\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now expand the approximant computed in the tensorized Chebyshev basis into standard monomial basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DynamicPolynomials, DataFrames\n",
    "ap = main_nd(n, d, poly_approx.coeffs) \n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "# Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "names = [x[i].name for i in 1:length(x)]\n",
    "open(loc, \"w\") do file\n",
    "    println(file, join(names, \", \"))\n",
    "    println(file, 0)\n",
    "end\n",
    "# Define the polynomial approximant \n",
    "PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "for i in 1:n\n",
    "    partial = differentiate(PolynomialApproximant, x[i])\n",
    "    partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "    open(loc, \"a\") do file\n",
    "        if i < n\n",
    "            println(file, string(partial_str, \",\"))\n",
    "        else\n",
    "            println(file, partial_str)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve with Msolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(`msolve -v 1 -f inputs.ms -o outputs.ms`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function average(X::Vector{Int})::Float64\n",
    "    return sum(X) / length(X)\n",
    "end\n",
    "\n",
    "# Process the file and get the points\n",
    "evaled = process_output_file(file_path_output)\n",
    "\n",
    "# Parse the points into correct format\n",
    "real_pts = []\n",
    "for pts in evaled\n",
    "    if typeof(pts)== Vector{Vector{Vector{BigInt}}}\n",
    "        X = parse_point(pts)\n",
    "    else \n",
    "        X = average.(pts) \n",
    "    end\n",
    "    push!(real_pts, Float64.(X))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort through the critical points, make sure they fall into the domain of definition. Make them into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# Colllect the critical points of the approximant \n",
    "h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "h_z = map(p -> f([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "df = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z= h_z) # Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PlotlyJS, Colors\n",
    "# Generate the grid and evaluate the function\n",
    "N = 60  # resolution of the grid\n",
    "x = range(-scale_factor, scale_factor, length=N)\n",
    "y = range(-scale_factor, scale_factor, length=N)\n",
    "z = [f([xi, yi]) for yi in y, xi in x]\n",
    "\n",
    "#Scatter plot the critical points of the approximant\n",
    "scatter_traces = [scatter(x=df.x, y=df.y, mode=\"markers\", marker_size=5, name=\"Critical Points\")]\n",
    "\n",
    "# Create the contour plot\n",
    "cp = contour(x=x, y=y, z=z, ncontours=40, colorscale=\"Viridis\", showscale=false)\n",
    "\n",
    "# Combine contour plot and scatter traces\n",
    "all_traces = [cp; scatter_traces...]\n",
    "\n",
    "# Customize layout to handle legend groups\n",
    "layout = Layout(\n",
    "    title=\"Scatter and Contour Plot\",\n",
    "    xaxis_title=\"X-axis\",\n",
    "    yaxis_title=\"Y-axis\",\n",
    "    legend=(tracegroupgap=10, groupclick=\"toggleitem\"),\n",
    "    height=800 # Increase the height to make room for the legend \n",
    ")\n",
    "\n",
    "# Display the combined plot with legend\n",
    "display(plot(all_traces, layout))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = surface(x=x, y=y, z=z)\n",
    "# Had to switch the coordinates of the critical points to match the surface plot for some reason. \n",
    "crit_pts = scatter3d(x=df.y, y=df.x, z=df.z, mode=\"markers\", marker_size=5, name=\"Critical Points\")\n",
    "\n",
    "# Layout for the plot\n",
    "layout = Layout(title=\"3D Plot of Trefethen function\",\n",
    "    scene=attr(\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"y\",\n",
    "        zaxis_title=\"f(x, y)\"),\n",
    "        height=800\n",
    ")\n",
    "# Display the plot layout,\n",
    "plot([sf,  crit_pts], layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
