{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate three graphs: \n",
    "- Histogram of Number of `loc_min` points were found, (so outputs of the Optim routine) and what percentage of them is within a small distance of a critical point of the approximant. As a function of the degree `d` of the approximant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/globtim`\n",
      "\u001b[91m\u001b[1mERROR: \u001b[22m\u001b[39mLoadError: MethodError: no method matching length(::ComputePipeline.Computed)\n",
      "The function `length` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "\u001b[0mClosest candidates are:\n",
      "\u001b[0m  length(\u001b[91m::Base.EnvDict\u001b[39m)\n",
      "\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4menv.jl:232\u001b[24m\u001b[39m\n",
      "\u001b[0m  length(\u001b[91m::LibGit2.GitBlob\u001b[39m)\n",
      "\u001b[0m\u001b[90m   @\u001b[39m \u001b[35mLibGit2\u001b[39m \u001b[90m~/.julia/juliaup/julia-1.11.6+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/LibGit2/src/\u001b[39m\u001b[90m\u001b[4mblob.jl:3\u001b[24m\u001b[39m\n",
      "\u001b[0m  length(\u001b[91m::ExponentialBackOff\u001b[39m)\n",
      "\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4merror.jl:271\u001b[24m\u001b[39m\n",
      "\u001b[0m  ...\n",
      "\n",
      "Stacktrace:\n",
      "  [1] \u001b[0m\u001b[1m_similar_shape\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mitr\u001b[39m::\u001b[0mComputePipeline.Computed, ::\u001b[0mBase.HasLength\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4marray.jl:663\u001b[24m\u001b[39m\n",
      "  [2] \u001b[0m\u001b[1m_collect\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mcont\u001b[39m::\u001b[0mUnitRange\u001b[90m{Int64}\u001b[39m, \u001b[90mitr\u001b[39m::\u001b[0mComputePipeline.Computed, ::\u001b[0mBase.HasEltype, \u001b[90misz\u001b[39m::\u001b[0mBase.HasLength\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4marray.jl:722\u001b[24m\u001b[39m\n",
      "  [3] \u001b[0m\u001b[1mcollect\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mitr\u001b[39m::\u001b[0mComputePipeline.Computed\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4marray.jl:716\u001b[24m\u001b[39m\n",
      "  [4] \u001b[0m\u001b[1mbroadcastable\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mComputePipeline.Computed\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase.Broadcast\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mbroadcast.jl:712\u001b[24m\u001b[39m\n",
      "  [5] \u001b[0m\u001b[1mbroadcasted\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mbroadcast.jl:1323\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      "  [6] \u001b[0m\u001b[1mdraw_plot\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mscene\u001b[39m::\u001b[0mMakie.Scene, \u001b[90mscreen\u001b[39m::\u001b[0mCairoMakie.Screen\u001b[90m{CairoMakie.IMAGE}\u001b[39m, \u001b[90mpoly\u001b[39m::\u001b[0mMakie.Poly\u001b[90m{Tuple{GeometryBasics.HyperRectangle{2, Int64}}}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[32mCairoMakie\u001b[39m \u001b[90m~/.julia/packages/CairoMakie/JchUZ/src/\u001b[39m\u001b[90m\u001b[4moverrides.jl:16\u001b[24m\u001b[39m\n",
      "  [7] \u001b[0m\u001b[1mcairo_draw\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mscreen\u001b[39m::\u001b[0mCairoMakie.Screen\u001b[90m{CairoMakie.IMAGE}\u001b[39m, \u001b[90mscene\u001b[39m::\u001b[0mMakie.Scene\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[32mCairoMakie\u001b[39m \u001b[90m~/.julia/packages/CairoMakie/JchUZ/src/\u001b[39m\u001b[90m\u001b[4minfrastructure.jl:49\u001b[24m\u001b[39m\n",
      "  [8] \u001b[0m\u001b[1mcolorbuffer\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mscreen\u001b[39m::\u001b[0mCairoMakie.Screen\u001b[90m{CairoMakie.IMAGE}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[32mCairoMakie\u001b[39m \u001b[90m~/.julia/packages/CairoMakie/JchUZ/src/\u001b[39m\u001b[90m\u001b[4mscreen.jl:375\u001b[24m\u001b[39m\n",
      "  [9] \u001b[0m\u001b[1mcolorbuffer\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mscreen\u001b[39m::\u001b[0mCairoMakie.Screen\u001b[90m{CairoMakie.IMAGE}\u001b[39m, \u001b[90mformat\u001b[39m::\u001b[0mMakie.ImageStorageFormat\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[36mMakie\u001b[39m \u001b[90m~/.julia/packages/Makie/6zcxH/src/\u001b[39m\u001b[90m\u001b[4mdisplay.jl:394\u001b[24m\u001b[39m\n",
      " [10] \u001b[0m\u001b[1m(::Makie.var\"#1789#1790\"{Bool, Module, @Kwargs{}, Makie.FigureAxisPlot, Makie.ImageStorageFormat})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[36mMakie\u001b[39m \u001b[90m~/.julia/packages/Makie/6zcxH/src/\u001b[39m\u001b[90m\u001b[4mdisplay.jl:486\u001b[24m\u001b[39m\n",
      " [11] \u001b[0m\u001b[1mlock\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mMakie.var\"#1789#1790\"\u001b[90m{Bool, Module, @Kwargs{}, Makie.FigureAxisPlot, Makie.ImageStorageFormat}\u001b[39m, \u001b[90ml\u001b[39m::\u001b[0mReentrantLock\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mlock.jl:232\u001b[24m\u001b[39m\n",
      " [12] \u001b[0m\u001b[1m#colorbuffer#1788\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m~/.julia/packages/Makie/6zcxH/src/\u001b[39m\u001b[90m\u001b[4mdisplay.jl:477\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [13] \u001b[0m\u001b[1mcolorbuffer\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m~/.julia/packages/Makie/6zcxH/src/\u001b[39m\u001b[90m\u001b[4mdisplay.jl:476\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [14] \u001b[0m\u001b[1mcolorbuffer\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mfig\u001b[39m::\u001b[0mMakie.FigureAxisPlot\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[36mMakie\u001b[39m \u001b[90m~/.julia/packages/Makie/6zcxH/src/\u001b[39m\u001b[90m\u001b[4mdisplay.jl:476\u001b[24m\u001b[39m\n",
      " [15] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m~/.julia/packages/Makie/6zcxH/precompile/\u001b[39m\u001b[90m\u001b[4mshared-precompile.jl:6\u001b[24m\u001b[39m\n",
      " [16] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mBase.jl:562\u001b[24m\u001b[39m\n",
      " [17] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m~/.julia/packages/CairoMakie/JchUZ/src/\u001b[39m\u001b[90m\u001b[4mCairoMakie.jl:1\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [18] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m~/.julia/packages/CairoMakie/JchUZ/src/\u001b[39m\u001b[90m\u001b[4mprecompiles.jl:15\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [19] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m~/.julia/packages/PrecompileTools/L8A3n/src/\u001b[39m\u001b[90m\u001b[4mworkloads.jl:78\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [20] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m~/.julia/packages/CairoMakie/JchUZ/src/\u001b[39m\u001b[90m\u001b[4mprecompiles.jl:11\u001b[24m\u001b[39m\n",
      " [21] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mBase.jl:562\u001b[24m\u001b[39m\n",
      " [22] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[32mCairoMakie\u001b[39m \u001b[90m~/.julia/packages/CairoMakie/JchUZ/src/\u001b[39m\u001b[90m\u001b[4mCairoMakie.jl:1\u001b[24m\u001b[39m\n",
      " [23] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m~/.julia/packages/CairoMakie/JchUZ/src/\u001b[39m\u001b[90m\u001b[4mCairoMakie.jl:37\u001b[24m\u001b[39m\n",
      " [24] \u001b[0m\u001b[1minclude\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mBase.jl:562\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n",
      " [25] \u001b[0m\u001b[1minclude_package_for_output\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90minput\u001b[39m::\u001b[0mString, \u001b[90mdepot_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mdl_load_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mload_path\u001b[39m::\u001b[0mVector\u001b[90m{String}\u001b[39m, \u001b[90mconcrete_deps\u001b[39m::\u001b[0mVector\u001b[90m{Pair{Base.PkgId, UInt128}}\u001b[39m, \u001b[90msource\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n",
      "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mloading.jl:2881\u001b[24m\u001b[39m\n",
      " [26] top-level scope\n",
      "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mstdin:6\u001b[24m\u001b[39m\n",
      "in expression starting at /Users/ghscholt/.julia/packages/Makie/6zcxH/precompile/shared-precompile.jl:6\n",
      "in expression starting at /Users/ghscholt/.julia/packages/CairoMakie/JchUZ/src/precompiles.jl:10\n",
      "in expression starting at /Users/ghscholt/.julia/packages/CairoMakie/JchUZ/src/CairoMakie.jl:1\n",
      "in expression starting at stdin:6\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile CairoMakie [13f3f980-e62b-5c42-98c6-ff1f3baf88f0] to \"/Users/ghscholt/.julia/compiled/v1.11/CairoMakie/jl_XxannU\".",
     "output_type": "error",
     "traceback": [
      "Failed to precompile CairoMakie [13f3f980-e62b-5c42-98c6-ff1f3baf88f0] to \"/Users/ghscholt/.julia/compiled/v1.11/CairoMakie/jl_XxannU\".\n",
      "\n",
      "Stacktrace:\n",
      "  [1] error(s::String)\n",
      "    @ Base ./error.jl:35\n",
      "  [2] compilecache(pkg::Base.PkgId, path::String, internal_stderr::IO, internal_stdout::IO, keep_loaded_modules::Bool; flags::Cmd, cacheflags::Base.CacheFlags, reasons::Dict{String, Int64}, loadable_exts::Nothing)\n",
      "    @ Base ./loading.jl:3174\n",
      "  [3] (::Base.var\"#1110#1111\"{Base.PkgId})()\n",
      "    @ Base ./loading.jl:2579\n",
      "  [4] mkpidlock(f::Base.var\"#1110#1111\"{Base.PkgId}, at::String, pid::Int32; kwopts::@Kwargs{stale_age::Int64, wait::Bool})\n",
      "    @ FileWatching.Pidfile ~/.julia/juliaup/julia-1.11.6+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/FileWatching/src/pidfile.jl:95\n",
      "  [5] #mkpidlock#6\n",
      "    @ ~/.julia/juliaup/julia-1.11.6+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/FileWatching/src/pidfile.jl:90 [inlined]\n",
      "  [6] trymkpidlock(::Function, ::Vararg{Any}; kwargs::@Kwargs{stale_age::Int64})\n",
      "    @ FileWatching.Pidfile ~/.julia/juliaup/julia-1.11.6+0.aarch64.apple.darwin14/share/julia/stdlib/v1.11/FileWatching/src/pidfile.jl:116\n",
      "  [7] #invokelatest#2\n",
      "    @ ./essentials.jl:1057 [inlined]\n",
      "  [8] invokelatest\n",
      "    @ ./essentials.jl:1052 [inlined]\n",
      "  [9] maybe_cachefile_lock(f::Base.var\"#1110#1111\"{Base.PkgId}, pkg::Base.PkgId, srcpath::String; stale_age::Int64)\n",
      "    @ Base ./loading.jl:3698\n",
      " [10] maybe_cachefile_lock\n",
      "    @ ./loading.jl:3695 [inlined]\n",
      " [11] _require(pkg::Base.PkgId, env::String)\n",
      "    @ Base ./loading.jl:2565\n",
      " [12] __require_prelocked(uuidkey::Base.PkgId, env::String)\n",
      "    @ Base ./loading.jl:2388\n",
      " [13] #invoke_in_world#3\n",
      "    @ ./essentials.jl:1089 [inlined]\n",
      " [14] invoke_in_world\n",
      "    @ ./essentials.jl:1086 [inlined]\n",
      " [15] _require_prelocked(uuidkey::Base.PkgId, env::String)\n",
      "    @ Base ./loading.jl:2375\n",
      " [16] macro expansion\n",
      "    @ ./loading.jl:2314 [inlined]\n",
      " [17] macro expansion\n",
      "    @ ./lock.jl:273 [inlined]\n",
      " [18] __require(into::Module, mod::Symbol)\n",
      "    @ Base ./loading.jl:2271\n",
      " [19] #invoke_in_world#3\n",
      "    @ ./essentials.jl:1089 [inlined]\n",
      " [20] invoke_in_world\n",
      "    @ ./essentials.jl:1086 [inlined]\n",
      " [21] require(into::Module, mod::Symbol)\n",
      "    @ Base ./loading.jl:2260\n",
      " [22] eval\n",
      "    @ ./boot.jl:430 [inlined]\n",
      " [23] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base ./loading.jl:2734\n",
      " [24] #invokelatest#2\n",
      "    @ ./essentials.jl:1055 [inlined]\n",
      " [25] invokelatest\n",
      "    @ ./essentials.jl:1052 [inlined]\n",
      " [26] (::VSCodeServer.var\"#217#218\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.149.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:24\n",
      " [27] withpath(f::VSCodeServer.var\"#217#218\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.149.2/scripts/packages/VSCodeServer/src/repl.jl:276\n",
      " [28] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}, params::VSCodeServer.NotebookRunCellArguments, token::VSCodeServer.CancellationTokens.CancellationToken)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.149.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:13\n",
      " [29] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::VSCodeServer.JSONRPC.Request)\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode/extensions/julialang.language-julia-1.149.2/scripts/packages/JSONRPC/src/typed.jl:68\n",
      " [30] serve_notebook(pipename::String, debugger_pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; error_handler::var\"#5#10\"{String})\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.149.2/scripts/packages/VSCodeServer/src/serve_notebook.jl:147\n",
      " [31] top-level scope\n",
      "    @ ~/.vscode/extensions/julialang.language-julia-1.149.2/scripts/notebook/notebook.jl:35"
     ]
    }
   ],
   "source": [
    "include(joinpath(dirname(Base.find_package(\"Globtim\")), \"..\", \".globtim\", \"notebook_setup.jl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_min, d_max = 2, 10  # Using max degree 4 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the legacy approach with load_function_params\n",
    "# Deuflhard_4d is already defined in Globtim\n",
    "params = load_function_params(\"Deuflhard_4d\")\n",
    "TR = test_input(Deuflhard_4d;\n",
    "    dim=params.dim,\n",
    "    center=params.center,\n",
    "    GN=params.num_samples,\n",
    "    sample_range=params.sample_range,\n",
    "    tolerance=params.tolerance)\n",
    "\n",
    "@polyvar(x[1:TR.dim]); # Define polynomial ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `CSV` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: CSV is loaded but not imported in the active module Main.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `CSV` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Hint: CSV is loaded but not imported in the active module Main.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W4sZmlsZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "# Load the pre-computed 4D critical points from the orthant analysis\n",
    "df_orthant_critical = CSV.read(\"../ForwardDiff_Certification/by_degree/data/4d_all_critical_points_orthant.csv\", DataFrame)\n",
    "\n",
    "# Extract just the coordinates and function values\n",
    "df_reference_points = DataFrame(\n",
    "    x1 = df_orthant_critical.x1,\n",
    "    x2 = df_orthant_critical.x2, \n",
    "    x3 = df_orthant_critical.x3,\n",
    "    x4 = df_orthant_critical.x4,\n",
    "    z = df_orthant_critical.function_value\n",
    ")\n",
    "\n",
    "println(\"Loaded $(nrow(df_reference_points)) reference critical points from orthant analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `df_reference_points` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `df_reference_points` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "display(df_reference_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Please run the cell that loads df_reference_points first!",
     "output_type": "error",
     "traceback": [
      "Please run the cell that loads df_reference_points first!\n",
      "\n",
      "Stacktrace:\n",
      " [1] error(s::String)\n",
      "   @ Base ./error.jl:35\n",
      " [2] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:6"
     ]
    }
   ],
   "source": [
    "# Analyze polynomial approximations for different degrees\n",
    "results = Dict{Int,Any}()\n",
    "\n",
    "# Make sure we have reference points loaded\n",
    "if !@isdefined(df_reference_points)\n",
    "    error(\"Please run the cell that loads df_reference_points first!\")\n",
    "end\n",
    "\n",
    "for d in d_min:d_max\n",
    "    println(\"Analyzing degree $d...\")\n",
    "    \n",
    "    # Construct polynomial for this degree\n",
    "    pol = Constructor(TR, d, basis=:chebyshev, verbose=false)\n",
    "    \n",
    "    # Extract actual degree (handle both Int and Tuple cases)\n",
    "    actual_degree = pol.degree isa Tuple ? pol.degree[2] : pol.degree\n",
    "    \n",
    "    # Solve polynomial system\n",
    "    solutions = solve_polynomial_system(x, 4, actual_degree, pol.coeffs, basis=:chebyshev)\n",
    "    \n",
    "    # Process critical points\n",
    "    df_crit = process_crit_pts(solutions, Deuflhard_4d, TR)\n",
    "    \n",
    "    # Apply BFGS refinement to critical points\n",
    "    refined_points = []\n",
    "    captured_flags = Bool[]\n",
    "    \n",
    "    for i in 1:nrow(df_crit)\n",
    "        pt = [df_crit[i, Symbol(\"x$j\")] for j in 1:4]\n",
    "        res = Optim.optimize(Deuflhard_4d, pt, BFGS(), \n",
    "                           Optim.Options(g_tol=1e-8, f_abstol=1e-20, x_abstol=1e-12))\n",
    "        \n",
    "        refined_pt = Optim.minimizer(res)\n",
    "        push!(refined_points, refined_pt)\n",
    "        \n",
    "        # Check if point is captured by comparing to reference critical points\n",
    "        min_dist_to_ref = Inf\n",
    "        for j in 1:nrow(df_reference_points)\n",
    "            ref_pt = [df_reference_points[j, Symbol(\"x$k\")] for k in 1:4]\n",
    "            dist = norm(refined_pt - ref_pt)\n",
    "            min_dist_to_ref = min(min_dist_to_ref, dist)\n",
    "        end\n",
    "        \n",
    "        # Point is captured if it's close to a reference critical point\n",
    "        push!(captured_flags, min_dist_to_ref < 0.001)  # Using tolerance of 0.001\n",
    "    end\n",
    "    \n",
    "    # Create dataframe with refined points\n",
    "    df_min = DataFrame()\n",
    "    for j in 1:4\n",
    "        df_min[!, Symbol(\"x$j\")] = [p[j] for p in refined_points]\n",
    "    end\n",
    "    df_min[!, :z] = [Deuflhard_4d(p) for p in refined_points]\n",
    "    df_min[!, :captured] = captured_flags\n",
    "    \n",
    "    # Store results in format expected by notebook functions\n",
    "    results[d] = (\n",
    "        df = df_crit,        # Critical points from polynomial\n",
    "        df_min = df_min,     # Refined points with captured flag\n",
    "        convergence_stats = (nrm = pol.nrm,),\n",
    "        discrete_l2 = pol.nrm\n",
    "    )\n",
    "    \n",
    "    println(\"  Found $(nrow(df_crit)) critical points, $(sum(captured_flags)) captured (using orthant reference)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "type Nothing has no field plot_discrete_l2",
     "output_type": "error",
     "traceback": [
      "type Nothing has no field plot_discrete_l2\n",
      "\n",
      "Stacktrace:\n",
      " [1] getproperty(x::Nothing, f::Symbol)\n",
      "   @ Base ./Base.jl:49\n",
      " [2] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X10sZmlsZQ==.jl:3"
     ]
    }
   ],
   "source": [
    "# Access the extension module directly\n",
    "const GlobtimExt = Base.get_extension(Globtim, :GlobtimCairoMakieExt)\n",
    "const plot_discrete_l2 = GlobtimExt.plot_discrete_l2\n",
    "const capture_histogram = GlobtimExt.capture_histogram\n",
    "const plot_convergence_analysis = GlobtimExt.plot_convergence_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the tensored 4d dataframe and load CSV data\n",
    "using IterTools\n",
    "using CSV\n",
    "\n",
    "function double_dataframe(df::DataFrame)\n",
    "    n = nrow(df)\n",
    "    pairs = collect(product(1:n, 1:n))\n",
    "\n",
    "    x1 = vec([df.x[j[1]] for j in pairs])\n",
    "    y1 = vec([df.y[j[1]] for j in pairs])\n",
    "    x2 = vec([df.x[j[2]] for j in pairs])\n",
    "    y2 = vec([df.y[j[2]] for j in pairs])\n",
    "\n",
    "    return DataFrame(x1=x1, x2=y1, x3=x2, x4=y2)\n",
    "end\n",
    "\n",
    "df_chebfun = CSV.read(\"../../data/matlab_critical_points/valid_points_deuflhard.csv\", DataFrame)\n",
    "df_4d = double_dataframe(df_chebfun);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `plot_discrete_l2` not defined in `Main`\nSuggestion: add an appropriate import or assignment. This global was declared but not assigned.\nHint: a global variable of this name also exists in Globtim.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `plot_discrete_l2` not defined in `Main`\n",
      "Suggestion: add an appropriate import or assignment. This global was declared but not assigned.\n",
      "Hint: a global variable of this name also exists in Globtim.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X12sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "fig_1 = plot_discrete_l2(results, d_min, d_max, 1)\n",
    "save(\"discrete_l2.pdf\", fig_1)\n",
    "display(fig_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching capture_histogram(::Dict{Int64, Any}, ::Int64, ::Int64, ::Int64; tol_dist::Float64, show_legend::Bool)\nThe function `capture_histogram` exists, but no method is defined for this combination of argument types.",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching capture_histogram(::Dict{Int64, Any}, ::Int64, ::Int64, ::Int64; tol_dist::Float64, show_legend::Bool)\n",
      "The function `capture_histogram` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "fig_2 = capture_histogram(results, d_min, d_max, 1, tol_dist=.1, show_legend=false)\n",
    "save(\"histogram.pdf\", fig_2)\n",
    "display(fig_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "type Nothing has no field histogram_enhanced",
     "output_type": "error",
     "traceback": [
      "type Nothing has no field histogram_enhanced\n",
      "\n",
      "Stacktrace:\n",
      " [1] getproperty(x::Nothing, f::Symbol)\n",
      "   @ Base ./Base.jl:49\n",
      " [2] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "# Add histogram_enhanced to the imported functions\n",
    "const histogram_enhanced = GlobtimExt.histogram_enhanced\n",
    "\n",
    "# Create enhanced histogram using orthant critical points\n",
    "fig_enhanced = histogram_enhanced(\n",
    "    results, \n",
    "    df_orthant_critical,  # Full theoretical critical points data\n",
    "    d_min, \n",
    "    d_max, \n",
    "    1,\n",
    "    tol_bfgs = 0.001,    # Tolerance for BFGS convergence\n",
    "    tol_raw = 0.1,       # Tolerance for raw points  \n",
    "    show_legend = true\n",
    ")\n",
    "save(\"histogram_enhanced.pdf\", fig_enhanced)\n",
    "display(fig_enhanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Comparison\n",
    "\n",
    "The **original histogram** (above) shows captured vs uncaptured based on whether BFGS refinement moved the point by less than 0.1.\n",
    "\n",
    "The **enhanced histogram** (above) specifically tracks convergence to the 9 theoretical minimizers:\n",
    "- **Blue bars**: BFGS points that converged to theoretical minimizers (tolerance = 0.001)  \n",
    "- **Green bars**: Raw polynomial critical points already close to theoretical minimizers (tolerance = 0.1)\n",
    "\n",
    "This enhanced view shows:\n",
    "1. How many of the polynomial's critical points actually lead to true minima after refinement\n",
    "2. How many raw critical points are already good approximations of minima (green)\n",
    "3. The polynomial degree needed to capture all 9 theoretical minimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "analyze_convergence_distances (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define helper function expected by plot_convergence_analysis\n",
    "function analyze_convergence_distances(df::DataFrame)\n",
    "    # For each critical point, compute distance to nearest other critical point\n",
    "    n_points = nrow(df)\n",
    "    x_cols = [col for col in names(df) if startswith(string(col), \"x\")]\n",
    "    n_dims = length(x_cols)\n",
    "    \n",
    "    min_distances = Float64[]\n",
    "    \n",
    "    for i in 1:n_points\n",
    "        point1 = [df[i, Symbol(\"x$j\")] for j in 1:n_dims]\n",
    "        min_dist = Inf\n",
    "        \n",
    "        for j in 1:n_points\n",
    "            if i != j\n",
    "                point2 = [df[j, Symbol(\"x$j\")] for j in 1:n_dims]\n",
    "                dist = norm(point1 - point2)\n",
    "                min_dist = min(min_dist, dist)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if isfinite(min_dist)\n",
    "            push!(min_distances, min_dist)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if isempty(min_distances)\n",
    "        return (maximum=0.0, average=0.0)\n",
    "    end\n",
    "    \n",
    "    return (\n",
    "        maximum=maximum(min_distances),\n",
    "        average=sum(min_distances) / length(min_distances)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching plot_convergence_analysis(::Dict{Int64, Any}, ::Int64, ::Int64, ::Int64; show_legend::Bool)\nThe function `plot_convergence_analysis` exists, but no method is defined for this combination of argument types.",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching plot_convergence_analysis(::Dict{Int64, Any}, ::Int64, ::Int64, ::Int64; show_legend::Bool)\n",
      "The function `plot_convergence_analysis` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X20sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "fig_3 = plot_convergence_analysis(results, d_min, d_max, 1, show_legend=true)\n",
    "# save(\"convergence_analysis.pdf\", fig_3)\n",
    "display(fig_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "type Nothing has no field histogram_minimizers_only",
     "output_type": "error",
     "traceback": [
      "type Nothing has no field histogram_minimizers_only\n",
      "\n",
      "Stacktrace:\n",
      " [1] getproperty(x::Nothing, f::Symbol)\n",
      "   @ Base ./Base.jl:49\n",
      " [2] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X21sZmlsZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "# Add histogram_minimizers_only to the imported functions\n",
    "const histogram_minimizers_only = GlobtimExt.histogram_minimizers_only\n",
    "\n",
    "# Create minimizers-only histogram\n",
    "fig_minima = histogram_minimizers_only(\n",
    "    results, \n",
    "    df_orthant_critical,\n",
    "    d_min, \n",
    "    d_max, \n",
    "    1,\n",
    "    tol_theoretical = 0.001,   # Tolerance for matching theoretical points\n",
    "    show_legend = false\n",
    ")\n",
    "save(\"histogram_minima_only.pdf\", fig_minima)\n",
    "display(fig_minima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizers-Only Histogram\n",
    "\n",
    "This histogram focuses exclusively on **minimum points** (where f < 1e-6), filtering out saddle points and maxima:\n",
    "\n",
    "- **Blue bars**: BFGS refined points that are minima (low function value)\n",
    "- **Green bars**: Raw polynomial critical points that are already minima  \n",
    "- **Dark blue bars**: BFGS minima that match theoretical minimizers\n",
    "- **Red dashed line**: The 9 theoretical minimizers we're trying to find\n",
    "\n",
    "This view shows:\n",
    "1. Not all polynomial critical points are minima (compare total points vs minima)\n",
    "2. Some raw polynomial points are already good minima approximations (green)\n",
    "3. Progress toward finding all 9 theoretical minimizers as degree increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "analyze_captured_distances (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define helper functions\n",
    "function compute_min_distances(df, df_check)\n",
    "    # Initialize array to store minimum distances\n",
    "    min_distances = Float64[]\n",
    "\n",
    "    # For each row in df, find distance to closest point in df_check\n",
    "    for i in 1:nrow(df)\n",
    "        point = [df[i, Symbol(\"x$j\")] for j in 1:4]  # Extract point coordinates\n",
    "        min_dist = Inf\n",
    "\n",
    "        # Compare with each point in df_check\n",
    "        for j in 1:nrow(df_check)\n",
    "            check_point = [df_check[j, Symbol(\"x$j\")] for j in 1:4]\n",
    "            dist = norm(point - check_point)  # Euclidean distance\n",
    "            min_dist = min(min_dist, dist)\n",
    "        end\n",
    "\n",
    "        push!(min_distances, min_dist)\n",
    "    end\n",
    "\n",
    "    return min_distances\n",
    "end\n",
    "\n",
    "function analyze_captured_distances(df, df_check)\n",
    "    distances = compute_min_distances(df, df_check)\n",
    "    return (\n",
    "        maximum=maximum(distances),\n",
    "        average=sum(distances) / length(distances)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_convergence_captured (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the plot_convergence_captured function\n",
    "function plot_convergence_captured(results, df_check, start_degree::Int, end_degree::Int, step::Int; show_legend::Bool=true)\n",
    "    degrees = start_degree:step:end_degree\n",
    "    max_distances = Float64[]\n",
    "    avg_distances = Float64[]\n",
    "\n",
    "    for d in degrees\n",
    "        x_cols = [col for col in names(results[d].df_min) if startswith(string(col), \"x\")]\n",
    "        df = results[d].df_min[:, x_cols]\n",
    "\n",
    "        stats = analyze_captured_distances(df, df_check)\n",
    "        push!(max_distances, stats.maximum)\n",
    "        push!(avg_distances, stats.average)\n",
    "    end\n",
    "\n",
    "    fig = Figure(size=(600, 400))\n",
    "\n",
    "    ax = Axis(fig[1, 1],\n",
    "        # xlabel removed per user request\n",
    "        # ylabel removed per user request\n",
    "        )\n",
    "\n",
    "    scatterlines!(ax, degrees, max_distances, label=\"Maximum\", color=:red)\n",
    "    scatterlines!(ax, degrees, avg_distances, label=\"Average\", color=:blue)\n",
    "\n",
    "    # Legend removed per user request - respect show_legend parameter\n",
    "    # if show_legend\n",
    "    #     axislegend(ax)\n",
    "    # end\n",
    "\n",
    "    return fig\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `df_reference_points` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `df_reference_points` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X25sZmlsZQ==.jl:3"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "# Use the reference critical points from orthant analysis instead of df_4d\n",
    "fig_4 = plot_convergence_captured(results, df_reference_points, d_min, d_max, 1, show_legend=false)\n",
    "save(\"convergence_captured_orthant.pdf\", fig_4)\n",
    "display(fig_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Capture Rate Summary (using orthant reference points) ===\n",
      "Degree | Total Points | Captured | Uncaptured | Capture Rate\n",
      "-------|--------------|----------|------------|-------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "KeyError: key 2 not found",
     "output_type": "error",
     "traceback": [
      "KeyError: key 2 not found\n",
      "\n",
      "Stacktrace:\n",
      " [1] getindex(h::Dict{Int64, Any}, key::Int64)\n",
      "   @ Base ./dict.jl:477\n",
      " [2] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X26sZmlsZQ==.jl:6"
     ]
    }
   ],
   "source": [
    "# Summary of capture rates with orthant reference points\n",
    "println(\"\\n=== Capture Rate Summary (using orthant reference points) ===\")\n",
    "println(\"Degree | Total Points | Captured | Uncaptured | Capture Rate\")\n",
    "println(\"-------|--------------|----------|------------|-------------\")\n",
    "for d in d_min:d_max\n",
    "    total = nrow(results[d].df_min)\n",
    "    captured = sum(results[d].df_min.captured)\n",
    "    uncaptured = total - captured\n",
    "    rate = captured / total * 100\n",
    "    println(\"   $d   |      $(lpad(total, 3))     |    $(lpad(captured, 3))   |     $(lpad(uncaptured, 3))    |   $(round(rate, digits=1))%\")\n",
    "end\n",
    "\n",
    "println(\"\\nNote: Points are considered 'captured' if they are within 0.001 distance\")\n",
    "println(\"of any reference critical point from the orthant analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Reference Point Coverage Analysis ===\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `df_reference_points` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `df_reference_points` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X30sZmlsZQ==.jl:3"
     ]
    }
   ],
   "source": [
    "# Analyze which reference points are being found\n",
    "println(\"\\n=== Reference Point Coverage Analysis ===\")\n",
    "println(\"Checking which of the $(nrow(df_reference_points)) reference points are found by degree 8...\")\n",
    "\n",
    "# For degree 8, check which reference points are matched\n",
    "d8_refined = results[8].df_min\n",
    "ref_found = falses(nrow(df_reference_points))\n",
    "\n",
    "for i in 1:nrow(df_reference_points)\n",
    "    ref_pt = [df_reference_points[i, Symbol(\"x$j\")] for j in 1:4]\n",
    "    \n",
    "    # Check if any refined point is close to this reference point\n",
    "    for j in 1:nrow(d8_refined)\n",
    "        refined_pt = [d8_refined[j, Symbol(\"x$k\")] for k in 1:4]\n",
    "        dist = norm(refined_pt - ref_pt)\n",
    "        if dist < 0.001\n",
    "            ref_found[i] = true\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Reference points found: $(sum(ref_found)) out of $(nrow(df_reference_points))\")\n",
    "println(\"Coverage: $(round(sum(ref_found)/nrow(df_reference_points)*100, digits=1))%\")\n",
    "\n",
    "# Show which types of points are missing\n",
    "if \"type_4d\" in names(df_orthant_critical)\n",
    "    println(\"\\nBreakdown by type:\")\n",
    "    for type in unique(df_orthant_critical.type_4d)\n",
    "        type_mask = df_orthant_critical.type_4d .== type\n",
    "        type_found = sum(ref_found[type_mask])\n",
    "        type_total = sum(type_mask)\n",
    "        println(\"  $type: $type_found/$type_total found ($(round(type_found/type_total*100, digits=1))%)\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Four Key Visualizations\n",
    "\n",
    "We've generated four important graphs to analyze the polynomial approximation quality:\n",
    "\n",
    "1. **Discrete L2 Norm** (`discrete_l2.pdf`): Shows how the approximation error decreases as polynomial degree increases\n",
    "\n",
    "2. **Original Histogram** (`histogram.pdf`): Shows captured vs uncaptured points based on BFGS movement distance\n",
    "\n",
    "3. **Enhanced Histogram** (`histogram_enhanced.pdf`): Tracks convergence to the 9 theoretical minimizers:\n",
    "   - Blue bars: BFGS refined points converging to minimizers\n",
    "   - Green bars: Raw polynomial critical points already near minimizers\n",
    "   \n",
    "4. **Minimizers-Only Histogram** (`histogram_minima_only.pdf`): Focuses only on minimum points:\n",
    "   - Shows which critical points are actual minima (f < 1e-6)\n",
    "   - Tracks progress toward finding all 9 theoretical minimizers\n",
    "   \n",
    "5. **Convergence Analysis** (`convergence_captured_orthant.pdf`): Shows maximum and average distances from refined points to the nearest theoretical critical point\n",
    "\n",
    "These visualizations demonstrate that:\n",
    "- Higher degree polynomials better approximate the function (lower L2 norm)\n",
    "- Not all critical points found by the polynomial are true minima\n",
    "- The polynomial approximation progressively captures more of the 9 theoretical minimizers as degree increases\n",
    "- Some polynomial degrees find many critical points but few are actual minima"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
