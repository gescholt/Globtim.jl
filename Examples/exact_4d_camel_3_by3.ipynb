{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camel_3_by_3 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Globtim\n",
    "using CSV\n",
    "using DataFrames\n",
    "include(\"../src/lib_func.jl\")\n",
    "\n",
    "# Load the dataframe from the CSV file\n",
    "df_2d = CSV.read(\"../data/camel_3_d6.csv\", DataFrame)\n",
    "\n",
    "# Constants and Parameters\n",
    "d = 3      # Degree \n",
    "const n, a, b = 4, 5, 1 \n",
    "const scale_factor = a / b  # Scaling constant, C is appears in `main_computation`, maybe it should be a parameter.\n",
    "const delta, alpha = .1 , 2 / 10  # Sampling parameters\n",
    "const tol_l2 = 500               # Define the tolerance for the L2-norm\n",
    "# const tol_l2 = 1e-0\n",
    "# The objective function\n",
    "\n",
    "f = camel_3_by_3 # Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `camel_3_by_3` function is the product `camel_3(x1,x2)*camel_3(x3,x4)`.\n",
    "Maybe not the best example for 4d since the minimas are so shallow and the magnitude of the function blows up around the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current L2-norm: 15077.847551104931\n",
      "Number of samples: 7\n",
      "current L2-norm: 4367.137375343813\n",
      "Number of samples: 9\n",
      "current L2-norm: 2335.2243566828693\n",
      "Number of samples: 12\n",
      "current L2-norm: 590.2587682348413\n",
      "Number of samples: 14\n",
      "attained the desired L2-norm: 390.9501611610721\n"
     ]
    }
   ],
   "source": [
    "while true # Potential infinite loop\n",
    "    global poly_approx = MainGenerate(f, n, d, delta, alpha, scale_factor, 0.2) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx.nrm < tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx.nrm)\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx.nrm)\n",
    "        println(\"Number of samples: \", poly_approx.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming x is already defined as @polyvar x[1:2]\n",
    "loc = \"inputs.ms\"\n",
    "# File path of the output file\n",
    "file_path_output = \"outputs.ms\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DynamicPolynomials, DataFrames\n",
    "ap = main_nd(n, d, poly_approx.coeffs)\n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "# Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "names = [x[i].name for i in 1:length(x)]\n",
    "open(loc, \"w\") do file\n",
    "    println(file, join(names, \", \"))\n",
    "    println(file, 0)\n",
    "end\n",
    "# Define the polynomial approximant \n",
    "PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "for i in 1:n\n",
    "    partial = differentiate(PolynomialApproximant, x[i])\n",
    "    partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "    open(loc, \"a\") do file\n",
    "        if i < n\n",
    "            println(file, string(partial_str, \",\"))\n",
    "        else\n",
    "            println(file, partial_str)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Optim.jl package to initialize step 3 and converge to the local minimizers.\n",
    "How do we know we have everything ? Use simple combinations of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- INPUT DATA ---------------\n",
      "#variables                       4\n",
      "#equations                       4\n",
      "#invalid equations               0\n",
      "field characteristic             0\n",
      "homogeneous input?               0\n",
      "signature-based computation      0\n",
      "monomial order                 DRL\n",
      "basis hash table resetting     OFF\n",
      "linear algebra option            2\n",
      "initial hash table size     131072 (2^17)\n",
      "max pair selection             ALL\n",
      "reduce gb                        1\n",
      "#threads                         1\n",
      "info level                       1\n",
      "generate pbm files               0\n",
      "------------------------------------------\n",
      "Dimension of quotient: 1296\n",
      "[1296, 146], Non trivial / Trivial = 11.27%\n",
      "Density of non-trivial part 90.85%\n",
      "Time spent to generate sequence (elapsed): 0.26 sec (1.88 Gops/sec)\n",
      "Time spent to compute eliminating polynomial (elapsed): 0.04 sec\n",
      "Elimination polynomial has degree 1296.\n",
      "\n",
      "Starts multi-modular computations\n",
      "{2}{4}{8}{16}{32}{64}{128}{256}{512}{1024}\n",
      "<Step:2/0.06/0.29>{2048}\n",
      "<Step:4/0.11/0.56>\n",
      "<Step:8/0.18/0.90>{4096}\n",
      "<Step:16/0.54/2.51>"
     ]
    },
    {
     "ename": "ProcessFailedException",
     "evalue": "failed process: Process(`msolve -v 1 -f inputs.ms -o outputs.ms`, ProcessSignaled(9)) [0]\n",
     "output_type": "error",
     "traceback": [
      "failed process: Process(`msolve -v 1 -f inputs.ms -o outputs.ms`, ProcessSignaled(9)) [0]\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] pipeline_error\n",
      "   @ ./process.jl:565 [inlined]\n",
      " [2] run(::Cmd; wait::Bool)\n",
      "   @ Base ./process.jl:480\n",
      " [3] run(::Cmd)\n",
      "   @ Base ./process.jl:477\n",
      " [4] top-level scope\n",
      "   @ ~/Globtim/Examples/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W6sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "run(`msolve -v 1 -f inputs.ms -o outputs.ms`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a Dataframe with only the critical points of the approximant $w_d$ which fall into the $[-1, 1]^4$ domain and rescale them to the original domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching getindex(::Nothing, ::Int64)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::Nothing, ::Int64)\n",
      "\n",
      "Stacktrace:\n",
      " [1] process_output_file(file_path::String)\n",
      "   @ Globtim ~/Globtim/src/ApproxConstruct.jl:146\n",
      " [2] top-level scope\n",
      "   @ ~/Globtim/Examples/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X11sZmlsZQ==.jl:6"
     ]
    }
   ],
   "source": [
    "function average(X::Vector{Int})::Float64\n",
    "    return sum(X) / length(X)\n",
    "end\n",
    "\n",
    "# Process the file and get the points\n",
    "evaled = process_output_file(file_path_output)\n",
    "\n",
    "# Parse the points into correct format\n",
    "real_pts = []\n",
    "for pts in evaled\n",
    "    if typeof(pts) == Vector{Vector{Vector{BigInt}}}\n",
    "        X = parse_point(pts)\n",
    "    else\n",
    "        X = average.(pts)\n",
    "    end\n",
    "    push!(real_pts, Float64.(X))\n",
    "end\n",
    "\n",
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1 && -1 < point[3] < 1 && -1 < point[4] < 1 \n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# Colllect the critical points of the approximant \n",
    "h_x1 = scale_factor * Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_x2 = scale_factor * Float64[point[2] for point in filtered_points] \n",
    "h_x3 = scale_factor * Float64[point[3] for point in filtered_points] \n",
    "h_x4 = scale_factor * Float64[point[4] for point in filtered_points] \n",
    "\n",
    "height = map(p -> f(p), zip(h_x1, h_x2, h_x3, h_x4)) # Compute the height of the critical points\n",
    "df = DataFrame(x1 = h_x1, x2 = h_x2, x3 = h_x3, x4 = h_x4, height = height); # Create a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to compute the distance between the critical points of the 2d function.\n",
    "\n",
    "The true \"exact\" critical points of the 2d `Camel3` function are stored in `df_2d`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `df` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `df` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Globtim/Examples/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:4"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "total_distance = Float64[]\n",
    "for i in 1:nrow(df)\n",
    "    distances_1 = [norm([df.x1[i], df.x2[i]] - [df_2d.x[j], df_2d.y[j]]) for j in 1:nrow(df_2d)]\n",
    "    distances_2 = [norm([df.x3[i], df.x4[i]] - [df_2d.x[j], df_2d.y[j]]) for j in 1:nrow(df_2d)]\n",
    "    # Compute distances to all points in df_2d\n",
    "    min_value_1, min_index_1 = findmin(distances_1)\n",
    "    min_value_2, min_index_2 = findmin(distances_2) \n",
    "\n",
    "    # Extract the corresponding points\n",
    "    point_1 = [df.x1[i], df.x2[i], df.x3[i], df.x4[i]]\n",
    "    point_2 = [df_2d.x[min_index_1], df_2d.y[min_index_1], df_2d.x[min_index_2], df_2d.y[min_index_2]]\n",
    "\n",
    "    # Compute total distance\n",
    "    tot_dist = norm(point_1 - point_2)\n",
    "    push!(total_distance, tot_dist)\n",
    "\n",
    "end\n",
    "df.total_distance = total_distance\n",
    "sorted_df = sort(df, :total_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `df` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `df` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Globtim/Examples/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "using Optim\n",
    "df.steps = zeros(nrow(df))\n",
    "df.converged = zeros(nrow(df))\n",
    "\n",
    "for i in 1:nrow(df)\n",
    "    # println(\"Optimizing for point $i\")\n",
    "    x0 = [df.x1[i], df.x2[i], df.x3[i], df.x4[i]]\n",
    "    #  + 0.2 * randn(Float64, 4)\n",
    "    res = Optim.optimize(f, x0, LBFGS(), Optim.Options(show_trace=false))\n",
    "    minimizer = Optim.minimizer(res)\n",
    "    min_value = Optim.minimum(res)\n",
    "    steps = res.iterations\n",
    "    converged = Optim.converged(res)\n",
    "    distance = norm(x0 - minimizer)\n",
    "    # df.dist_to_loc_min[i] = distance\n",
    "    df.steps[i] = steps\n",
    "    df.converged[i] = converged\n",
    "    # summary(res)\n",
    "end\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
