{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is a small parcel to work on, with a nice contourplot with critical points and minima found after initiating local method and then a 3d plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camel (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Globtim\n",
    "include(\"../../src/lib_func.jl\")\n",
    "\n",
    "# Constants and Parameters\n",
    "d = 6 # Initial Degree \n",
    "const n, a, b = 2, 5, 1 \n",
    "const scale_factor = a / b       # Scaling factor appears in `main_computation`, maybe it should be a parameter.\n",
    "const delta, alpha = .9 , 8 / 10  # Sampling parameters\n",
    "const tol_l2 = 3e-4             # Define the tolerance for the L2-norm\n",
    "\n",
    "# Change name of output file!\n",
    "\n",
    "f = camel # Objective function\n",
    "# f = camel_3 # Objective function 3 humps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to also return the number of samples used to generate the sample set. It is annoying that the error goes up while the degree has increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attained the desired L2-norm: 1.6461730875298986e-13\n"
     ]
    }
   ],
   "source": [
    "while true # Potential infinite loop\n",
    "    global poly_approx = MainGenerate(f, 2, d, delta, alpha, scale_factor, 0.2) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx.nrm < tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx.nrm)\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx.nrm)\n",
    "        println(\"Number of samples: \", poly_approx.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now expand the approximant computed in the tensorized Chebyshev basis into standard monomial basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DynamicPolynomials, HomotopyContinuation, ProgressLogging, DataFrames\n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "ap = main_nd(n, d, poly_approx.coeffs) \n",
    "# Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "PolynomialApproximant = sum(Float64.(ap) .* MonomialVector(x, 0:d)) # Convert coefficients to Float64 for homotopy continuation\n",
    "grad = differentiate.(PolynomialApproximant, x)\n",
    "sys = System(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the system of partial derivatives using HomotopyContinuation. Note that without the conversion to floating point coefficients, there is an issue if we try to use BigFloats directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_sol_lstsq = HomotopyContinuation.solve(sys)\n",
    "real_pts = HomotopyContinuation.real_solutions(Real_sol_lstsq; only_real=true, multiple_results=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort through the critical points, make sure they fall into the domain of definition. Make them into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# Colllect the critical points of the approximant \n",
    "h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "h_z = map(p -> f([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "df = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z= h_z) # Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames.to_markdown(df, \"output.md\") # Save the critical points to a markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PlotlyJS, Colors\n",
    "# Generate the grid and evaluate the function\n",
    "N = 60  # resolution of the grid\n",
    "x = range(-scale_factor, scale_factor, length=N)\n",
    "y = range(-scale_factor, scale_factor, length=N)\n",
    "z = [f([xi, yi]) for yi in y, xi in x]\n",
    "\n",
    "#Scatter plot the critical points of the approximant\n",
    "scatter_traces = [scatter(x=df.x, y=df.y, mode=\"markers\", marker_size=5, name=\"Critical Points\")]\n",
    "\n",
    "# Create the contour plot\n",
    "cp = contour(x=x, y=y, z=z, ncontours=40, colorscale=\"Viridis\", showscale=false)\n",
    "\n",
    "# Combine contour plot and scatter traces\n",
    "all_traces = [cp; scatter_traces...]\n",
    "\n",
    "# Customize layout to handle legend groups\n",
    "layout = Layout(\n",
    "    title=\"Scatter and Contour Plot\",\n",
    "    xaxis_title=\"X-axis\",\n",
    "    yaxis_title=\"Y-axis\",\n",
    "    legend=(tracegroupgap=10, groupclick=\"toggleitem\"),\n",
    "    height=800, # Increase the height to make room for the legend \n",
    "    width=1000\n",
    ")\n",
    "\n",
    "# Display the combined plot with legend\n",
    "display(plot(all_traces, layout))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = surface(x=x, y=y, z=z)\n",
    "# Had to switch the coordinates of the critical points to match the surface plot for some reason. \n",
    "crit_pts = scatter3d(x=df.y, y=df.x, z=df.z, mode=\"markers\", marker_size=5, name=\"Critical Points\")\n",
    "\n",
    "# Layout for the plot\n",
    "layout = Layout(title=\"3D Plot of Trefethen function\",\n",
    "    scene=attr(\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"y\",\n",
    "        zaxis_title=\"f(x, y)\"),\n",
    "        height=800\n",
    ")\n",
    "# Display the plot layout,\n",
    "plot([sf,  crit_pts], layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using CSV \n",
    "\n",
    "# CSV.write(\"camel_3_d$d.csv\", df)\n",
    "# CSV.write(\"../data/camel_d$d.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
