{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m "
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "using Revise\n",
    "Pkg.activate(joinpath(@__DIR__, \"../../\"))\n",
    "using Globtim\n",
    "using DynamicPolynomials, DataFrames\n",
    "using GLMakie\n",
    "using StaticArrays\n",
    "# Constants and Parameters\n",
    "const n, a, b = 3, 12, 100 \n",
    "const scale_factor = a / b   # Scaling factor appears in `main_computation`\n",
    "f = tref_3d # Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the number of samples used to generate the approximant. It is annoying that the error goes up while the degree has increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = [0.0, 0.0, 0.0];\n",
    "d = 14 # initial degree \n",
    "SMPL = 30 # Number of samples\n",
    "TR = test_input(f, \n",
    "                dim = n,\n",
    "                center=center,\n",
    "                GN=SMPL, \n",
    "                sample_range=scale_factor, \n",
    "                degree_max =d+4\n",
    "                )\n",
    "pol_cheb = Constructor(TR, d, basis=:chebyshev)\n",
    "# pol_lege = Constructor(TR, d, basis=:legendre);\n",
    "\n",
    "@polyvar(x[1:n]); # Define polynomial ring "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the system of partial derivatives using `Homotopy_COntinuation.jl`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cheb = solve_and_parse(pol_cheb, x, f, TR)\n",
    "pts_cheb = solve_polynomial_system(x, TR.dim, d, pol_cheb.coeffs; basis=:chebyshev)\n",
    "df_cheb = process_crit_pts(pts_cheb, f, TR)\n",
    "sort!(df_cheb, :z, rev=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = scale_factor * generate_grid(3, 100);  # 3D grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1 = create_level_set_visualization(f, grid, df_cheb, (-3.0, 6.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_2 = create_level_set_animation(f, grid, df_cheb, (-3.0, 6.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLMakie.closeall() # Close all previous plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(BigInt(2)^64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1: add samples around one point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function augment_grid_around_point(\n",
    "    point::Vector{Float64},\n",
    "    TR,\n",
    "    N_sub::Int=5;\n",
    "    cube_side_ratio::Float64=0.1,\n",
    "    basis::Symbol=:legendre  # Changed default to legendre\n",
    ")::Array{SVector{3,Float64},3}\n",
    "\n",
    "    sample_range = TR.sample_range\n",
    "    side_length = sample_range * cube_side_ratio\n",
    "    half_side = side_length / 2\n",
    "\n",
    "    # Using legendre (equally spaced) points\n",
    "    x_coords = range(point[1] - half_side, point[1] + half_side, length=N_sub)\n",
    "    y_coords = range(point[2] - half_side, point[2] + half_side, length=N_sub)\n",
    "    z_coords = range(point[3] - half_side, point[3] + half_side, length=N_sub)\n",
    "\n",
    "    [SVector{3,Float64}(x, y, z)\n",
    "     for x in x_coords,\n",
    "     y in y_coords,\n",
    "     z in z_coords]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this the proper structure for merging the samples together? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_loc_1 = augment_grid_around_point(center, TR, 2)\n",
    "gr_loc_2 = augment_grid_around_point([.1,.2,.3], TR, 2)\n",
    "println(size(gr_loc_1))\n",
    "println(size(gr_loc_2))\n",
    "merged = cat(gr_loc_1, gr_loc_2, dims=3)\n",
    "println(size(merged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function 2: Create augmented grid using DataFrame points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_augmented_grid(\n",
    "    base_grid::Array{SVector{3,Float64},3},\n",
    "    df_cheb::DataFrame;\n",
    "    N_sub::Int=5,\n",
    "    basis::Symbol=:legendre\n",
    ")::Array{SVector{3,Float64},3}\n",
    "\n",
    "    # Calculate new grid size\n",
    "    current_size = size(base_grid, 1)  # Should be 40\n",
    "    points_to_add = nrow(df_cheb) * N_sub^3\n",
    "    new_side_length = ceil(Int, ∛(current_size^3 + points_to_add))\n",
    "\n",
    "    # Create new grid array\n",
    "    new_grid = Array{SVector{3,Float64},3}(undef, new_side_length, new_side_length, new_side_length)\n",
    "\n",
    "    # Copy base grid\n",
    "    for i in 1:size(base_grid, 1), j in 1:size(base_grid, 2), k in 1:size(base_grid, 3)\n",
    "        new_grid[i, j, k] = base_grid[i, j, k]\n",
    "    end\n",
    "\n",
    "    # Add sub-sampled points in the remaining space\n",
    "    current_idx = size(base_grid, 1) * size(base_grid, 2) * size(base_grid, 3)\n",
    "\n",
    "    for row in eachrow(df_cheb)\n",
    "        point = [row.x1, row.x2, row.x3]\n",
    "        sub_grid = augment_grid_around_point(point, TR, N_sub; basis=basis)\n",
    "\n",
    "        for point in vec(sub_grid)\n",
    "            idx_i = (current_idx ÷ new_side_length^2) + 1\n",
    "            idx_j = ((current_idx % new_side_length^2) ÷ new_side_length) + 1\n",
    "            idx_k = (current_idx % new_side_length) + 1\n",
    "\n",
    "            if idx_i <= new_side_length && idx_j <= new_side_length && idx_k <= new_side_length\n",
    "                new_grid[idx_i, idx_j, idx_k] = point\n",
    "                current_idx += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return new_grid\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base grid with 40 points per dimension\n",
    "GN = 50  # This will give us 40 points per dimension (GN + 1)\n",
    "base_grid = generate_grid_small_n(3, GN, basis=:legendre)  # 40×40×40 grid\n",
    "augmented_grid = create_augmented_grid(base_grid, df_cheb)\n",
    "println(size(base_grid))\n",
    "println(size(augmented_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function augment_samples_around_point(\n",
    "    point::Vector{Float64},\n",
    "    TR,\n",
    "    N_sub::Int=5;\n",
    "    cube_side_ratio::Float64=0.1\n",
    ")::Vector{SVector{3,Float64}}\n",
    "    sample_range = TR.sample_range\n",
    "    side_length = sample_range * cube_side_ratio\n",
    "    half_side = side_length / 2\n",
    "\n",
    "    # Create local sampling points\n",
    "    x_coords = range(point[1] - half_side, point[1] + half_side, length=N_sub)\n",
    "    y_coords = range(point[2] - half_side, point[2] + half_side, length=N_sub)\n",
    "    z_coords = range(point[3] - half_side, point[3] + half_side, length=N_sub)\n",
    "\n",
    "    # Return as a flat vector of points\n",
    "    return vec([SVector{3,Float64}(x, y, z) for x in x_coords, y in y_coords, z in z_coords])\n",
    "end\n",
    "\n",
    "function create_augmented_samples(\n",
    "    base_points::Vector{SVector{3,Float64}},\n",
    "    df_cheb::DataFrame;\n",
    "    N_sub::Int=5\n",
    ")::Vector{SVector{3,Float64}}\n",
    "    # Initialize with base points\n",
    "    augmented_points = Set{SVector{3,Float64}}()\n",
    "\n",
    "    # Add base points\n",
    "    for point in base_points\n",
    "        push!(augmented_points, point)\n",
    "    end\n",
    "\n",
    "    # Add additional samples around critical points\n",
    "    for row in eachrow(df_cheb)\n",
    "        point = [row.x1, row.x2, row.x3]\n",
    "        local_samples = augment_samples_around_point(point, TR, N_sub)\n",
    "        for sample in local_samples\n",
    "            push!(augmented_points, sample)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return collect(augmented_points)\n",
    "end\n",
    "\n",
    "# Usage example:\n",
    "# Convert your original grid to a vector if needed:\n",
    "# base_points = vec(base_grid)\n",
    "# augmented_points = create_augmented_samples(base_points, df_cheb)\n",
    "# println(\"Original points: $(length(base_points))\")\n",
    "# println(\"Augmented points: $(length(augmented_points))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_points = vec(base_grid)\n",
    "augmented_points = create_augmented_samples(base_points, df_cheb)\n",
    "println(\"Original points: $(length(base_points))\")\n",
    "println(\"Augmented points: $(length(augmented_points))\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not correctly increasing the size of the sample grid. I thought we already had something efficient to augment the samples per level set, maybe the slider is much easier... In the end, I just want the Makie plot with the slider moving really slowly and a bit of rotation and output the result of that ---> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_level_set_visualization(f, grid, df_cheb, (-3.0, 6.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_level_set_visualization(f, augmented_grid, df_cheb, (-3.0, 6.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3: Produce Video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_level_sets_video(\n",
    "    f,\n",
    "    grid::Array{SVector{3,T},3},\n",
    "    z_range::Tuple{Real,Real},\n",
    "    output_path::String;\n",
    "    fps::Int=30,\n",
    "    duration::Float64=20.0,\n",
    "    tolerance::Float64=0.1\n",
    ") where {T<:AbstractFloat}\n",
    "\n",
    "    n_frames = round(Int, fps * duration)\n",
    "    level_sequence = range(z_range[1], z_range[2], length=n_frames)\n",
    "\n",
    "    fig = Figure()\n",
    "    ax = Axis3(fig[1, 1],\n",
    "        title=\"Level Set Animation\",\n",
    "        xlabel=\"x₁\",\n",
    "        ylabel=\"x₂\",\n",
    "        zlabel=\"x₃\")\n",
    "\n",
    "    grid_points = vec(grid)\n",
    "    x_range = extrema(p[1] for p in grid_points)\n",
    "    y_range = extrema(p[2] for p in grid_points)\n",
    "    z_range_grid = extrema(p[3] for p in grid_points)\n",
    "\n",
    "    limits!(ax, x_range..., y_range..., z_range_grid...)\n",
    "\n",
    "    values = reshape(map(f, grid_points), size(grid))\n",
    "    level_points = Observable(Point3f[])\n",
    "    point_alphas = Observable(Float32[])\n",
    "\n",
    "    scatter!(ax, level_points,\n",
    "        color=:blue,\n",
    "        markersize=0.8,\n",
    "        alpha=point_alphas)  # Changed from opacity to alpha\n",
    "\n",
    "    function update_visualization(level::T) where {T<:AbstractFloat}\n",
    "        all_points = Point3f[]\n",
    "        all_alphas = Float32[]\n",
    "\n",
    "        for (point, value) in zip(grid_points, vec(values))\n",
    "            dist_from_level = abs(value - level)\n",
    "            if dist_from_level ≤ tolerance\n",
    "                alpha = 1.0 - (dist_from_level / tolerance)\n",
    "                push!(all_points, Point3f(point...))\n",
    "                push!(all_alphas, Float32(alpha))\n",
    "            end\n",
    "        end\n",
    "\n",
    "        level_points[] = all_points\n",
    "        point_alphas[] = all_alphas\n",
    "    end\n",
    "\n",
    "    record(fig, output_path, 1:n_frames; framerate=fps) do frame\n",
    "        current_level = level_sequence[frame]\n",
    "        update_visualization(current_level)\n",
    "\n",
    "        ax.azimuth[] = 1.7π + 0.4 * sin(2π * frame / n_frames)\n",
    "        ax.elevation[] = π / 4 + 0.3 * cos(2π * frame / n_frames)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Try it:\n",
    "z_range = (-3.0, 6.0)\n",
    "make_level_sets_video(tref_3d, augmented_grid, z_range, \"level_sets_video.mp4\"; tolerance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_range = (-3.0, 6.0)\n",
    "video_level_sets(tref_3d, augmented_grid, z_range, \"level_sets_video.mp4\"; tolerance=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the level of the grid, we just sample more densely in `x, y, z` space around each of the critical points from the dataframe ? --> we reuse the grid to generate all the level sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLMakie.closeall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
