{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is a small parcel to work on, with a nice contourplot with critical points and minima found after initiating local method and then a 3d plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Globtim\n",
    "include(\"../src/lib_func.jl\")\n",
    "\n",
    "# Constants and Parameters\n",
    "d = 1 # Initial Degree \n",
    "const n, a, b = 2, 11, 10 \n",
    "const scale_factor = a / b       # Scaling factor appears in `main_computation`, maybe it should be a parameter.\n",
    "const delta, alpha = .5 , 1 / 10  # Sampling parameters # Delta used to be too big \n",
    "const tol_l2 = 1e-4            # Define the tolerance for the L2-norm\n",
    "const sample_scale = 1.0\n",
    "\n",
    "f = Deuflhard # Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may assume that when we have access to exact evaluations, we would want to have a small $L^2$-norm tolerance `tol_l2 = 5e-4` and high probability of computing an accurate discrete $L^2$-norm `alpha= 1/10`.\n",
    "\n",
    "We need to also return the number of samples used to generate the sample set. It is annoying that the error goes up while the degree has increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while true # Potential infinite loop\n",
    "    global poly_approx = MainGenerate(f, 2, d, delta, alpha, scale_factor, sample_scale) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx.nrm < tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx.nrm)\n",
    "        println(\"Degree :$d \")\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx.nrm)\n",
    "        println(\"Number of samples: \", poly_approx.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end\n",
    "println(\"current L2-norm: \", poly_approx.nrm)\n",
    "println(\"Number of samples: \", poly_approx.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now expand the approximant computed in the tensorized Chebyshev basis into standard monomial basis and construct the system of partials for MSolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = \"inputs.ms\"\n",
    "# File path of the output file\n",
    "file_path_output = \"outputs.ms\";\n",
    "\n",
    "using DynamicPolynomials, DataFrames\n",
    "ap = main_nd(n, d, poly_approx.coeffs)\n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "# Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "names = [x[i].name for i in 1:length(x)]\n",
    "open(loc, \"w\") do file\n",
    "    println(file, join(names, \", \"))\n",
    "    println(file, 0)\n",
    "end\n",
    "# Define the polynomial approximant \n",
    "PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "for i in 1:n\n",
    "    partial = differentiate(PolynomialApproximant, x[i])\n",
    "    partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "    open(loc, \"a\") do file\n",
    "        if i < n\n",
    "            println(file, string(partial_str, \",\"))\n",
    "        else\n",
    "            println(file, partial_str)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the system of partial derivatives using `Msolve`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(`msolve -v 1 -f inputs.ms -o outputs.ms`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort through the critical points, make sure they fall into the domain of definition. Make them into a Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function average(X::Vector{Int})::Float64\n",
    "    return sum(X) / length(X)\n",
    "end\n",
    "\n",
    "# Process the file and get the points\n",
    "evaled = process_output_file(file_path_output)\n",
    "\n",
    "# Parse the points into correct format\n",
    "real_pts = []\n",
    "for pts in evaled\n",
    "    if typeof(pts) == Vector{Vector{Vector{BigInt}}}\n",
    "        X = parse_point(pts)\n",
    "    else\n",
    "        X = average.(pts)\n",
    "    end\n",
    "    push!(real_pts, Float64.(X))\n",
    "end\n",
    "\n",
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# Colllect the critical points of the approximant \n",
    "h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "h_z = map(p -> f([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "df = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z= h_z); # Create a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to generate the plot of the critical points over the sample set $\\mathcal{S}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PlotlyJS, Colors\n",
    "# Extract coordinates and function values\n",
    "coords = poly_approx.scale_factor * poly_approx.grid\n",
    "z_coords = poly_approx.z\n",
    "\n",
    "# Plot the 3D scatter plot if the dimensions are 2\n",
    "if size(coords)[2] == 2\n",
    "    scatter_trace = scatter3d(\n",
    "        x=coords[:, 1],\n",
    "        y=coords[:, 2],\n",
    "        z=z_coords,\n",
    "        mode=\"markers\",\n",
    "        marker=attr(\n",
    "            size=1,\n",
    "            color=z_coords,\n",
    "            colorscale=\"Viridis\"\n",
    "        ),\n",
    "        name=\"Sampled Data\"\n",
    "    )\n",
    "    println(\"Plotting 3D scatter plot\")\n",
    "\n",
    "    # Create the scatter3d trace\n",
    "    # Had to switch the coordinates of the critical points to match the surface plot for some reason. \n",
    "    crit_pts = scatter3d(\n",
    "        x=df.y,\n",
    "        y=df.x,\n",
    "        z=df.z,\n",
    "        mode=\"markers\",\n",
    "        marker=attr(\n",
    "            size=10,\n",
    "            color=\"red\"\n",
    "        ),\n",
    "        name=\"Exact Critical Points\"\n",
    "    )\n",
    "\n",
    "    layout = Layout(\n",
    "        title=\"Deuflhard Scatter Plot of Sample Points\",\n",
    "        scene=attr(\n",
    "            xaxis=attr(title=\"X-axis\"),\n",
    "            yaxis=attr(title=\"Y-axis\"),\n",
    "            zaxis=attr(title=\"Z-axis\")),\n",
    "        height=1200\n",
    "    )\n",
    "    plt1 = Plot([scatter_trace, crit_pts],layout)\n",
    "    display(plt1)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Degree: $d\")\n",
    "println(\"current L2-norm: \", poly_approx.nrm)\n",
    "println(\"Number of samples: \", poly_approx.N)\n",
    "savefig(plt1, \"../data/figures/3d_Deuflhard.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a Random Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We equip the evaluations of `CrossInTray` with a Gaussian noise. We set the standard deviation `stddev`to `5.0`.\n",
    "Observation so far: low sensitivity to changing `alpha`, the probability on the discrete $L^2$-norm, we observe that the number of samples generated does not change drastically w.r.t. `alpha`. \n",
    "In a first scenario, we only require a low probability `1 - alpha_noise` of the discrete $L^2$-norm reaching the tolerance set by `noisy_tol_l2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "# Define the noisy version of the objective function\n",
    "function noisy_Deuflhard(xx::Vector{Float64}; mean::Float64=0.0, stddev::Float64=5.0)::Float64\n",
    "    noise = rand(Normal(mean, stddev))\n",
    "    return Deuflhard(xx) + noise\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_tol_l2 = 5e-2        # Define the noise affected tolerance for the L2-norm\n",
    "\n",
    "f_noisy = noisy_Deuflhard\n",
    "d = 1\n",
    "\n",
    "while true # Potential infinite loop\n",
    "    global poly_approx_noisy = MainGenerate(f_noisy, 2, d, delta, alpha, scale_factor, sample_scale) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx_noisy.nrm < noisy_tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx_noisy.nrm)\n",
    "        println(\"Degree: $d\")\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx_noisy.nrm)\n",
    "        println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end\n",
    "println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "\n",
    "ap = main_nd(n, d, poly_approx_noisy.coeffs)\n",
    "\n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "# Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "names = [x[i].name for i in 1:length(x)]\n",
    "open(loc, \"w\") do file\n",
    "    println(file, join(names, \", \"))\n",
    "    println(file, 0)\n",
    "end\n",
    "# Define the polynomial approximant \n",
    "PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "for i in 1:n\n",
    "    partial = differentiate(PolynomialApproximant, x[i])\n",
    "    partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "    open(loc, \"a\") do file\n",
    "        if i < n\n",
    "            println(file, string(partial_str, \",\"))\n",
    "        else\n",
    "            println(file, partial_str)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "run(`msolve -v 0 -f inputs.ms -o outputs.ms`)\n",
    "# Process the file and get the points\n",
    "evaled = process_output_file(file_path_output)\n",
    "\n",
    "# Parse the points into correct format\n",
    "real_pts = []\n",
    "for pts in evaled\n",
    "    if typeof(pts) == Vector{Vector{Vector{BigInt}}}\n",
    "        X = parse_point(pts)\n",
    "    else\n",
    "        X = average.(pts)\n",
    "    end\n",
    "    push!(real_pts, Float64.(X))\n",
    "end\n",
    "\n",
    "\n",
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# Colllect the critical points of the approximant \n",
    "h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "\n",
    "# Here we should evaluate on the noiseless function to compare with previous results\n",
    "h_z = map(p -> f([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "\n",
    "df_noisy = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z=h_z); # Create a DataFrame\n",
    "\n",
    "coords = poly_approx_noisy.scale_factor * poly_approx_noisy.grid\n",
    "z_coords = poly_approx_noisy.z\n",
    "\n",
    "# Plot the 3D scatter plot if the dimensions are 2\n",
    "if size(coords)[2] == 2\n",
    "    scatter_trace = scatter3d(\n",
    "        x=coords[:, 1],\n",
    "        y=coords[:, 2],\n",
    "        z=z_coords,\n",
    "        mode=\"markers\",\n",
    "        marker=attr(\n",
    "            size=1,\n",
    "            color=z_coords,\n",
    "            colorscale=\"Viridis\"\n",
    "        ),\n",
    "        name=\"Sampled Noisy Data\"\n",
    "    )\n",
    "    # Had to switch the coordinates of the critical points to match the surface plot for some reason. \n",
    "    crit_pts_noisy = scatter3d(\n",
    "        x=df_noisy.y,\n",
    "        y=df_noisy.x,\n",
    "        z=df_noisy.z,\n",
    "        mode=\"markers\",\n",
    "        marker=attr(\n",
    "            size=8,\n",
    "            color=\"orange\"\n",
    "        ),\n",
    "        name=\"Critical Points\"\n",
    "    )\n",
    "\n",
    "    layout = Layout(\n",
    "        title=\"3D Scatter Plot of Sample Points\",\n",
    "        scene=attr(\n",
    "            xaxis=attr(title=\"X-axis\"),\n",
    "            yaxis=attr(title=\"Y-axis\"),\n",
    "            zaxis=attr(title=\"Z-axis\")),\n",
    "        height=1200\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt2 = Plot([scatter_trace, crit_pts_noisy, crit_pts], layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"L2 tolerance: $noisy_tol_l2\")\n",
    "println(\"Degree: $d\")\n",
    "println(\"current L2-norm: \", poly_approx_noisy.nrm)\n",
    "println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "savefig(plt2, \"../data/figures/noisy_3d_Deuflhard.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1\n",
    "noisy_tol_l2 = 2.0e-2        # Define the noise affected tolerance for the L2-norm\n",
    "while true # Potential infinite loop\n",
    "    global poly_approx_noisy = MainGenerate(f_noisy, 2, d, delta, alpha, scale_factor, sample_scale) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx_noisy.nrm < noisy_tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx_noisy.nrm)\n",
    "        println(\"Degree: $d\")\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx_noisy.nrm)\n",
    "        println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "        global d += 1\n",
    "    end\n",
    "end\n",
    "println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "\n",
    "ap = main_nd(n, d, poly_approx_noisy.coeffs)\n",
    "\n",
    "@polyvar(x[1:n]) # Define polynomial ring \n",
    "# Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "names = [x[i].name for i in 1:length(x)]\n",
    "open(loc, \"w\") do file\n",
    "    println(file, join(names, \", \"))\n",
    "    println(file, 0)\n",
    "end\n",
    "# Define the polynomial approximant \n",
    "PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "for i in 1:n\n",
    "    partial = differentiate(PolynomialApproximant, x[i])\n",
    "    partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "    open(loc, \"a\") do file\n",
    "        if i < n\n",
    "            println(file, string(partial_str, \",\"))\n",
    "        else\n",
    "            println(file, partial_str)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "run(`msolve -v 0 -f inputs.ms -o outputs.ms`)\n",
    "# Process the file and get the points\n",
    "evaled = process_output_file(file_path_output)\n",
    "\n",
    "# Parse the points into correct format\n",
    "real_pts = []\n",
    "for pts in evaled\n",
    "    if typeof(pts) == Vector{Vector{Vector{BigInt}}}\n",
    "        X = parse_point(pts)\n",
    "    else\n",
    "        X = average.(pts)\n",
    "    end\n",
    "    push!(real_pts, Float64.(X))\n",
    "end\n",
    "\n",
    "# Repeat, could be made ito a function. \n",
    "\n",
    "condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# Colllect the critical points of the approximant \n",
    "h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "\n",
    "# Here we should evaluate on the noiseless function to compare with previous results\n",
    "h_z = map(p -> f([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "\n",
    "df_noisy = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z=h_z); # Create a DataFrame\n",
    "\n",
    "coords = poly_approx_noisy.scale_factor * poly_approx_noisy.grid\n",
    "z_coords = poly_approx_noisy.z\n",
    "\n",
    "# Plot the 3D scatter plot if the dimensions are 2\n",
    "if size(coords)[2] == 2\n",
    "    scatter_trace = scatter3d(\n",
    "        x=coords[:, 1],\n",
    "        y=coords[:, 2],\n",
    "        z=z_coords,\n",
    "        mode=\"markers\",\n",
    "        marker=attr(\n",
    "            size=1,\n",
    "            color=z_coords,\n",
    "            colorscale=\"Viridis\"\n",
    "        ),\n",
    "        name=\"Sampled Noisy Data\"\n",
    "    )\n",
    "    # Had to switch the coordinates of the critical points to match the surface plot for some reason. \n",
    "    crit_pts_noisy = scatter3d(\n",
    "        x=df_noisy.y,\n",
    "        y=df_noisy.x,\n",
    "        z=df_noisy.z,\n",
    "        mode=\"markers\",\n",
    "        marker=attr(\n",
    "            size=8,\n",
    "            color=\"orange\"\n",
    "        ),\n",
    "        name=\"Critical Points\"\n",
    "    )\n",
    "\n",
    "    layout = Layout(\n",
    "        title=\"3D Scatter Plot of Sample Points\",\n",
    "        scene=attr(\n",
    "            xaxis=attr(title=\"X-axis\"),\n",
    "            yaxis=attr(title=\"Y-axis\"),\n",
    "            zaxis=attr(title=\"Z-axis\")),\n",
    "        height=1200\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt3 = Plot([scatter_trace, crit_pts_noisy, crit_pts], layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"L2 tolerance: $noisy_tol_l2\")\n",
    "println(\"Degree: $d\")\n",
    "println(\"current L2-norm: \", poly_approx_noisy.nrm)\n",
    "println(\"Number of samples: \", poly_approx_noisy.N)\n",
    "savefig(plt3, \"../data/figures/noisy_tol_up_3d_Deuflhard.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_noisy = plot([sf, crit_pts_noisy], layout)\n",
    "# savefig(plt, \"../data/figures/Noisy_Deuflhard.html\")\n",
    "# savefig(plt1, \"../data/figures/Deuflhard_surf_exact.html\")\n",
    "# savefig(plt_noisy, \"../data/figures/Deuflhard_surf_noisy_pts.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
