{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need is a small parcel to work on, with a nice contourplot with critical points and minima found after initiating local method and then a 3d plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/globtim`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"../../.\")\n",
    "using Globtim\n",
    "using DynamicPolynomials, DataFrames\n",
    "using ProgressLogging\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deuflhard (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Constants and Parameters\n",
    "const n, a, b = 2, 12, 10\n",
    "const scale_factor = a / b   # Scaling factor appears in `main_computation`, maybe it should be a parameter.\n",
    "const delta, alpha = 0.5, 1 / 10  # Sampling parameters\n",
    "const tol_l2 = 3e-4            # Define the tolerance for the L2-norm\n",
    "f = Deuflhard # Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f([0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may assume that when we have access to exact evaluations, we would want to have a small $L^2$-norm tolerance `tol_l2 = 5e-4` and high probability of computing an accurate discrete $L^2$-norm `alpha= 1/10`.\n",
    "\n",
    "We need to also return the number of samples used to generate the sample set. It is annoying that the error goes up while the degree has increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current L2-norm: 0.5289850410278208\n",
      "current L2-norm: 0.49248824331534263\n"
     ]
    }
   ],
   "source": [
    "d = 8 # Initial Degree \n",
    "SMPL = 40 # Number of samples\n",
    "TR = test_input(f, \n",
    "                dim = n,\n",
    "                center=[0.0, 0.0],\n",
    "                GN=SMPL \n",
    "                )\n",
    "pol_cheb = Constructor(TR, d, basis=:chebyshev)\n",
    "pol_lege = Constructor(TR, d, basis=:legendre);\n",
    "\n",
    "@polyvar(x[1:n]); # Define polynomial ring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension m of the vector space: 45\n",
      "\n",
      "=== Starting MSolve Parser (dimension: 2) ===\n",
      "Processed 13 points (0.0s)\n",
      "Dimension m of the vector space: 45\n",
      "\n",
      "=== Starting MSolve Parser (dimension: 2) ===\n",
      "Processed 13 points (0.0s)\n",
      "Processing point 1 of 9\n",
      "Optimization has converged within bounds: \u001b[32m✓\u001b[0m\n",
      "Processing point 2 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 3 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 4 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 5 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 6 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 7 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 8 of 9\n",
      "Optimization has converged within bounds: \u001b[32m✓\u001b[0m\n",
      "Processing point 9 of 9\n",
      "Optimization has converged within bounds: \u001b[32m✓\u001b[0m\n",
      "Processing point 1 of 9\n",
      "Optimization has converged within bounds: \u001b[32m✓\u001b[0m\n",
      "Processing point 2 of 9\n",
      "Optimization has converged within bounds: \u001b[32m✓\u001b[0m\n",
      "Processing point 3 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 4 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 5 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 6 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 7 of 9\n",
      "Optimization status: \u001b[31m✗\u001b[0m (outside bounds)\n",
      "Processing point 8 of 9\n",
      "Optimization has converged within bounds: \u001b[32m✓\u001b[0m\n",
      "Processing point 9 of 9\n",
      "Optimization has converged within bounds: \u001b[32m✓\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\u001b[1m9×8 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m x1           \u001b[0m\u001b[1m x2           \u001b[0m\u001b[1m z          \u001b[0m\u001b[1m y1           \u001b[0m\u001b[1m y2           \u001b[0m\u001b[1m clo\u001b[0m ⋯\n",
       "     │\u001b[90m Float64      \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Boo\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ -3.90326e-17   6.88014e-16  4.0         -3.90326e-17   6.88014e-16   tr ⋯\n",
       "   2 │ -0.410543     -0.410543     2.5947      -0.459896     -0.459896      tr\n",
       "   3 │  0.410543      0.410543     2.5947      -0.256625      1.01625       tr\n",
       "   4 │ -0.453474      0.93908      0.259065    -0.256625      1.01625       tr\n",
       "   5 │  0.453474     -0.93908      0.259065     0.256625     -1.01625       tr ⋯\n",
       "   6 │ -0.93908       0.453474     0.259065    -1.01625       0.256625      tr\n",
       "   7 │  0.93908      -0.453474     0.259065     1.01625      -0.256625      tr\n",
       "   8 │  0.750171     -0.750171     0.00669131   0.741152     -0.741152      tr\n",
       "   9 │ -0.750171      0.750171     0.00669131  -0.741152      0.741152      tr ⋯\n",
       "\u001b[36m                                                               3 columns omitted\u001b[0m, \u001b[1m3×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m x2           \u001b[0m\u001b[1m x1           \u001b[0m\u001b[1m value       \u001b[0m\u001b[1m captured \u001b[0m\n",
       "     │\u001b[90m Float64      \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Bool     \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────\n",
       "   1 │  6.88014e-16  -3.90326e-17  4.0              true\n",
       "   2 │ -0.741152      0.741152     1.09329e-18      true\n",
       "   3 │  0.741152     -0.741152     1.09359e-18      true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cheb = solve_and_parse(pol_cheb, x, f, TR)\n",
    "sort!(df_cheb, :z, rev=true)\n",
    "df_lege = solve_and_parse(pol_lege, x, f, TR, basis=:legendre)\n",
    "sort!(df_lege, :z, rev=true)\n",
    "\n",
    "df_cheb, df_min_cheb = analyze_critical_points(f, df_cheb, TR, tol_dist=1.0)\n",
    "df_lege, df_min_lege = analyze_critical_points(f, df_lege, TR, tol_dist=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the system of partial derivatives using `Msolve`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching msolve_parser(::String, ::typeof(Deuflhard), ::Float64, ::Int64)\nThe function `msolve_parser` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  msolve_parser(::String, ::Function, !Matched::test_input)\n   @ Globtim ~/globtim/src/ParsingOutputs.jl:49\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching msolve_parser(::String, ::typeof(Deuflhard), ::Float64, ::Int64)\n",
      "The function `msolve_parser` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Closest candidates are:\n",
      "  msolve_parser(::String, ::Function, !Matched::test_input)\n",
      "   @ Globtim ~/globtim/src/ParsingOutputs.jl:49\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/globtim/Examples/Notebooks/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X11sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "df_cheb = msolve_parser(\"outputs.ms\", f, scale_factor, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant Main.scale_factor. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GLMakie.Screen(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using GLMakie\n",
    "\n",
    "# Extract coordinates and function values\n",
    "# Change the coordinates to uniform grid\n",
    "coords = pol_cheb.scale_factor * pol_cheb.grid\n",
    "z_coords = pol_cheb.z\n",
    "\n",
    "if size(coords)[2] == 2  # Plot if the dimensions are 2\n",
    "    fig = Figure(size=(800, 600))\n",
    "    ax = Axis3(fig[1, 1], title=\"Deuflhard Function\",\n",
    "        xlabel=\"X-axis\", ylabel=\"Y-axis\", zlabel=\"Z-axis\")\n",
    "\n",
    "    # Scale the domain\n",
    "    scale_factor = pol_cheb.scale_factor  # Using the scale factor from your polynomial\n",
    "\n",
    "    # Define threshold for switching between scatter and surface\n",
    "    point_threshold = 1000  # Adjust this value based on your needs\n",
    "    sample_fraction = 0.2   # Fraction of points to use if exceeding threshold\n",
    "\n",
    "    if length(z_coords) > point_threshold\n",
    "        # Create a regular grid for surface plotting\n",
    "        x_unique = sort(unique(coords[:, 1]))\n",
    "        y_unique = sort(unique(coords[:, 2]))\n",
    "\n",
    "        # Determine grid dimensions\n",
    "        nx = length(x_unique)\n",
    "        ny = length(y_unique)\n",
    "\n",
    "        # Reshape data into a grid\n",
    "        z_grid = reshape(z_coords, nx, ny)\n",
    "\n",
    "        # Create surface plot with scaled domain\n",
    "        surface!(ax, scale_factor .* x_unique, scale_factor .* y_unique, z_grid,\n",
    "            colormap=:viridis,\n",
    "            transparency=true,\n",
    "            alpha=0.8)\n",
    "\n",
    "        # Sample a fraction of points for scatter overlay\n",
    "        n_points = length(z_coords)\n",
    "        sample_indices = rand(1:n_points, Int(floor(n_points * sample_fraction)))\n",
    "\n",
    "        # Plot sampled scatter points with scaled domain\n",
    "        scatter!(ax, scale_factor .* coords[sample_indices, 1],\n",
    "            scale_factor .* coords[sample_indices, 2],\n",
    "            z_coords[sample_indices],\n",
    "            markersize=2,\n",
    "            color=:black,\n",
    "            label=\"Sampled Data Points\")\n",
    "    else\n",
    "        # Original scatter plot for smaller datasets with scaled domain\n",
    "        scatter!(ax, scale_factor .* coords[:, 1],\n",
    "            scale_factor .* coords[:, 2],\n",
    "            z_coords,\n",
    "            markersize=2,\n",
    "            color=:black,\n",
    "            label=\"Sampled Data Core\")\n",
    "\n",
    "        scatter!(ax, scale_factor .* coords[:, 1],\n",
    "            scale_factor .* coords[:, 2],\n",
    "            z_coords,\n",
    "            markersize=4,\n",
    "            color=z_coords,\n",
    "            colormap=:viridis,\n",
    "            label=\"Sampled Data Halo\")\n",
    "    end\n",
    "\n",
    "    # Plot the critical points with scaled domain\n",
    "    scatter!(ax, scale_factor .* df_cheb.x1,\n",
    "        scale_factor .* df_cheb.x2,\n",
    "        df_cheb.z,\n",
    "        markersize=10,\n",
    "        color=:orange,\n",
    "        label=\"Chebyshev approximant critical points\")\n",
    "\n",
    "    # scatter!(ax, scale_factor .* df_lege.x1,\n",
    "    #     scale_factor .* df_lege.x2,\n",
    "    #     df_lege.z,\n",
    "    #     markersize=10,\n",
    "    #     color=:yellow,\n",
    "    #     label=\"Legendre approximant critical points\")\n",
    "\n",
    "    display(fig)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
