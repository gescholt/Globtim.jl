{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mixture of $N =10$ random Gaussians centered in $[-1,1]^n$ \n",
    "$$\n",
    "f_{\\mu,\\sigma}(x, y) = \\sum_{i=1}^{N} \\frac{1}{\\sigma_i\\sqrt{2\\pi}}\\exp\\left(-\\frac{(x-\\mu_i)^2}{2\\sigma_i^2}\\right)\n",
    "$$\n",
    " is defined over the square $[-1, 1]^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Globtim.jl`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0e-6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"../../../.\")\n",
    "using Globtim\n",
    "\n",
    "# Constants and Parameters\n",
    "d = 1 # Initial Degree \n",
    "const n, a, b = 3, 1, 1 \n",
    "const scale_factor = a / b       # Scaling factor appears in `main_computation`, maybe it should be a parameter.\n",
    "const delta, alpha = .5 , 8 / 10  # Sampling parameters\n",
    "const tol_l2 = 1.e-6             # Define the tolerance for the L2-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "params = init_gaussian_params(n, N, 0.4)\n",
    "# Create a closure that captures params\n",
    "rand_gaussian_closure = (x) -> rand_gaussian(x, params)\n",
    "f = rand_gaussian_closure; # Function to be optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of `poly_approx` is `ApproxPoly`.\n",
    "It has fields: \n",
    "    `\n",
    "    \n",
    "    ApproxPoly::{T<:Number}\n",
    "    coeffs::Vector{T} \n",
    "    degree::Int\n",
    "    nrm::Float64\n",
    "    N::Int\n",
    "    scale_factor::Float64\n",
    "    grid::Matrix{Float64}\n",
    "    z::Vector{Float64}\n",
    "    ` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal degree: 4\n",
      "Optimal L2-norm: 0.0002613491715253416\n",
      "Optimal number of samples: 21\n",
      "optimal polynomial: [0.001678398186634644, -0.0002651968977090733, -0.002732237094956925, 0.0010187811942785811, -0.0011673279961386164, 0.0009497098147135598, 0.0025182791343234087, -0.0012199908699920188, 0.0005234444548009591, 0.0023393837838675277, 0.0012606189161794138, -0.00015861363943195053, -0.002019376584251966, -0.0008121422069703141, 0.0007497596984938905, -0.000888393415339814, -0.0023023987890348706, 0.0004130113428931972, 0.0016797133184820428, -0.0028318386518459667]\n",
      "optimal polynomial: Float64\n"
     ]
    }
   ],
   "source": [
    "while true && d < 4# Potential infinite loop\n",
    "    global poly_approx = MainGenerate(f, n, d, delta, alpha, scale_factor, 1.) # computes the approximant in Chebyshev basis\n",
    "    if poly_approx.nrm < tol_l2\n",
    "        println(\"attained the desired L2-norm: \", poly_approx.nrm)\n",
    "        break\n",
    "    else\n",
    "        println(\"current L2-norm: \", poly_approx.nrm)\n",
    "        println(\"Number of samples: \", poly_approx.N)\n",
    "        println(\"Current degree: \", d)\n",
    "        global d += 1\n",
    "    end\n",
    "end;\n",
    "println(\"Optimal degree: \", d)\n",
    "println(\"Optimal L2-norm: \", poly_approx.nrm)\n",
    "println(\"Optimal number of samples: \", poly_approx.N)\n",
    "println(\"optimal polynomial: \",poly_approx.coeffs)\n",
    "println(\"optimal polynomial: \",eltype(poly_approx.coeffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run some analysis on the approximation of the function $f_{\\mu,\\sigma}$ by a polynomial of degree $d$. We want to measure the distribution of the error. Compare with a uniform grid and a Chebyshev grid. We shall run statistics on the error distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "using IterTools\n",
    "\n",
    "function uniform_grid(n; range_min=-1.0, range_max=1.0, num_points_per_dim=10)\n",
    "    # Create a range of points for each dimension\n",
    "    ranges = [range(range_min, stop=range_max, length=num_points_per_dim) for _ in 1:n]\n",
    "\n",
    "    # Generate the Cartesian product of the ranges to create the grid\n",
    "    grid_points = collect(IterTools.product(ranges...))\n",
    "    # Convert the grid points to a matrix where each row is a point\n",
    "    uniform_grid_matrix = reduce(hcat, map(x -> collect(x), grid_points))'\n",
    "    # Print the grid points\n",
    "    uniform_grid_vectors = [collect(row) for row in eachrow(uniform_grid_matrix)]\n",
    "    return uniform_grid_vectors\n",
    "end\n",
    "\n",
    "test_grid = uniform_grid(n)\n",
    "f_values_uniform = f.(test_grid);\n",
    "\n",
    "poly_approx.grid\n",
    "chebyshev_grid_vectors = [collect(row) for row in eachrow(poly_approx.grid)]\n",
    "f_values_chebyshev = f.(chebyshev_grid_vectors);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLMakie\n",
    "\n",
    "# Extract coordinates and function values\n",
    "coords = poly_approx.scale_factor * poly_approx.grid\n",
    "x_coords = coords[:, 1]\n",
    "y_coords = coords[:, 2]\n",
    "z_coords = coords[:, 3]\n",
    "\n",
    "# Set a threshold for \"close to zero\" values\n",
    "threshold = 0.1  # Adjust as necessary\n",
    "\n",
    "# Filter data based on proximity to zero\n",
    "mask = abs.(f_values_chebyshev) .> threshold\n",
    "filtered_x = x_coords[mask]\n",
    "filtered_y = y_coords[mask]\n",
    "filtered_z = z_coords[mask]\n",
    "filtered_f_values = f_values_chebyshev[mask]\n",
    "\n",
    "# Normalize the filtered_f_values to the range [0, 1]\n",
    "min_f_value = minimum(filtered_f_values)\n",
    "max_f_value = maximum(filtered_f_values)\n",
    "normalized_f_values = (filtered_f_values .- min_f_value) ./ (max_f_value - min_f_value)\n",
    "\n",
    "# Plot the filtered points with varying transparency\n",
    "fig = Figure()\n",
    "ax = Axis3(fig[1, 1], title=\"Scatter Plot of Coordinates\", xlabel=\"X\", ylabel=\"Y\", zlabel=\"Z\")\n",
    "\n",
    "scatter!(\n",
    "    ax, filtered_x, filtered_y, filtered_z,\n",
    "    markersize=5,\n",
    "    color=normalized_f_values,\n",
    "    colormap=:viridis)\n",
    "\n",
    "# Display the plot\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_values = map(z -> abs(z) < threshold ? 0.2 : 0.0, filtered_f_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n",
      "└ @ Makie /Users/ghscholt/.julia/packages/Makie/6c4lt/src/scenes.jl:229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GLMakie.Screen(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_combined = Figure(resolution = (1600, 400))\n",
    "ax_combined_chebyshev = Axis(fig_combined[1, 1], title=\"Histogram of f_values (Chebyshev)\", xlabel=\"f(x)\", ylabel=\"Frequency\")\n",
    "ax_combined_uniform = Axis(fig_combined[1, 2], title=\"Histogram of f_values (Uniform)\", xlabel=\"f(x)\", ylabel=\"Frequency\")\n",
    "\n",
    "# Plot the histograms\n",
    "hist!(ax_combined_chebyshev, f_values_chebyshev, bins=120, color=:blue)\n",
    "hist!(ax_combined_uniform, f_values_uniform, bins=120, color=:red)\n",
    "\n",
    "display(fig_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pol"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using DynamicPolynomials, DataFrames\n",
    "using HomotopyContinuation, ProgressLogging\n",
    "\n",
    "@polyvar(x[1:n]) \n",
    "\"# Quick dirty fix the degree -1. But main_nd checks if the dimension is correct.\"\n",
    "pol = main_nd(x, n, d-1, poly_approx.coeffs) # Quick dirty fix the degree -1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the evaluations of the polynomial, in order to then plot the distribution of the errors too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1069-element Vector{Polynomial{DynamicPolynomials.Commutative{DynamicPolynomials.CreationOrder}, Graded{LexOrder}, BigFloat}}:\n",
       " 0.003392780074047647783226231134638732523451054879502789983196403659027782183637417\n",
       " 0.002946932135646556584012790016804021152457390084627577956678612656021082157587984\n",
       " 0.003029344468199942273735501224779692327880081181273125586401766098904771704926342\n",
       " 0.004367358074624776316952839313970502696300289672406444193040090445080799061328028\n",
       " 0.004465443809318496543870315552463134886737340383227610644200353233828475150719688\n",
       " 0.004150873615919429251602999862633397600350269232381481447980539225529744571307686\n",
       " 0.005901315093755349897785194907204816736523511794692122364871757228714991184625115\n",
       " 0.006009762397845448979604980507595686503289472174551632945845496678740072220726437\n",
       " 0.00316500891654540808597758304759552457989825360720620422527593987139494675626776\n",
       " 0.003826442482232979555874692357575346436498132535330008713284827149614991909761452\n",
       " ⋮\n",
       " 0.002820643695226683178975313983198064256898056064232631469993457999374544223781386\n",
       " 0.003345799359298996100792131248833114362003456392616922379308242327580740128668585\n",
       " 0.00380990845515002155546093171214107933138792512763389336908970234485522790548117\n",
       " 0.00192194013928840118444850217547574689455697994610402709252654933960578103116501\n",
       " 0.002155722339333517341743161151797681579228335164720589788763938330659028540584043\n",
       " 0.002527555634961853440256333073938991135194969074886062518099419273765592227048299\n",
       " 0.003014659348492596086665454641620133045724847922268845158356232681328386378664941\n",
       " 0.003566696452228388238083954178432679993476633761893003615063072110842407535461623\n",
       " 0.0041120244980699896343621846843681767604267938939353865229139078577797975105166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_cheb = [subs(pol, x[1] => p[1], x[2] => p[2], x[3] => p[3]) for p in chebyshev_grid_vectors]\n",
    "result_cheb_mask = result_cheb[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = differentiate.(pol, x)\n",
    "sys = System(grad)\n",
    "println(\"The system is of degree: \", d - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using WGLMakie\n",
    "\n",
    "# fig = Figure()\n",
    "# ax = Axis3(fig[1, 1], title=\"Function f on Uniform Grid\", xlabel=\"X\", ylabel=\"Y\", zlabel=\"f(x)\")\n",
    "\n",
    "# # Extract the x, y, and z coordinates from the grid\n",
    "# x_coords = test_grid[1, :]\n",
    "# y_coords = test_grid[2, :]\n",
    "# z_coords = test_grid[3, :]\n",
    "\n",
    "# # Plot the points with the function values as the color\n",
    "# scatter!(ax, x_coords, y_coords, z_coords, markersize=5, color=f_values, colormap=:viridis)\n",
    "\n",
    "# # Display the plot\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real_sol_lstsq = HomotopyContinuation.solve(sys)\n",
    "# real_pts = HomotopyContinuation.real_solutions(Real_sol_lstsq; only_real=true, multiple_results=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function condition(point::Vector{Float64}, n::Int)::Bool\n",
    "#     return all(-1 < point[i] < 1 for i in 1:n)\n",
    "# end\n",
    "# # condition(point) = -1 < point[1] < 1 && -1 < point[2] < 1\n",
    "# # filtered_points = filter(condition, real_pts) # Filter points using the filter function\n",
    "# filtered_points = filter(p -> condition(p, n), real_pts) # Filter points using the condition function\n",
    "\n",
    "# # Colllect the critical points of the approximant \n",
    "# # h_x = Float64[point[1] for point in filtered_points] # Initialize the x vector for critical points of approximant\n",
    "# # h_y = Float64[point[2] for point in filtered_points] # Initialize the y vector\n",
    "# # h_z = map(p -> f([p[1], p[2]]), zip(scale_factor * h_x, scale_factor * h_y))\n",
    "# # df = DataFrame(x=scale_factor * h_x, y=scale_factor * h_y, z=h_z) # Create a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat solving with exact method, compare timing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc = \"inputs.ms\"\n",
    "# # File path of the output file\n",
    "# file_path_output = \"outputs.ms\";\n",
    "\n",
    "# using DynamicPolynomials, DataFrames\n",
    "# ap = main_nd(n, d, poly_approx.coeffs)\n",
    "# @polyvar(x[1:n]) # Define polynomial ring \n",
    "# # Expand the polynomial approximant to the standard monomial basis in the Lexicographic order w.r.t x\n",
    "# names = [x[i].name for i in 1:length(x)]\n",
    "# open(loc, \"w\") do file\n",
    "#     println(file, join(names, \", \"))\n",
    "#     println(file, 0)\n",
    "# end\n",
    "# # Define the polynomial approximant \n",
    "# PolynomialApproximant = sum(ap .* MonomialVector(x, 0:d))\n",
    "# for i in 1:n\n",
    "#     partial = differentiate(PolynomialApproximant, x[i])\n",
    "#     partial_str = replace(string(partial), \"//\" => \"/\")\n",
    "#     open(loc, \"a\") do file\n",
    "#         if i < n\n",
    "#             println(file, string(partial_str, \",\"))\n",
    "#         else\n",
    "#             println(file, partial_str)\n",
    "#         end\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# # Optimize the collected entries \n",
    "# using Optim\n",
    "# for i in 1:nrow(df)\n",
    "#     println(\"Optimizing for point $i\")\n",
    "#     x0 = [df.x[i], df.y[i]]\n",
    "#     res = Optim.optimize(f, x0, LBFGS(), Optim.Options(show_trace=true))\n",
    "#     minimizer = Optim.minimizer(res)\n",
    "#     min_value = Optim.minimum(res)\n",
    "#     steps = res.iterations\n",
    "#     converged = Optim.converged(res)\n",
    "#     distance = norm(x0 - minimizer)\n",
    "#     println(summary(res))\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should plot the polynomial approximant too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
