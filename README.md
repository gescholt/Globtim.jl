# Globtim - Global Optimization via Polynomial Approximation

A Julia package for global optimization using polynomial approximation methods, with comprehensive HPC benchmarking infrastructure and production-ready cluster deployment.

## ğŸ¯ Current Status: CORE INFRASTRUCTURE OPERATIONAL âœ…

### âœ… Fully Functional HPC Infrastructure
- **Three-Tier Architecture**: Local â†’ Fileserver (mack) â†’ HPC Cluster (falcon) âœ… VERIFIED
- **SLURM Job Execution**: 7 successful jobs executed and monitored âœ… VERIFIED
- **Function Evaluation**: Mathematical functions evaluated successfully âœ… VERIFIED
- **Automated Monitoring**: Real-time job tracking and result collection âœ… VERIFIED
- **File Recovery**: All outputs automatically collected to local machine âœ… VERIFIED
- **NFS Integration**: Cluster nodes access fileserver seamlessly âœ… VERIFIED

### âš ï¸ Julia Environment Challenges
- **Package Installation**: 300+ packages installed but quota limits prevent precompilation
- **Globtim Loading**: Complex dependencies require workarounds (--compiled-modules=no)
- **Performance Impact**: Uncompiled modules may affect execution speed


> ğŸš¨ **CRITICAL: HPC Workflow - READ THIS FIRST** ğŸš¨
>
> **Step 1: Code Management (via fileserver mack)**
> - Upload/modify code: `ssh scholten@mack`, work in `~/globtim_hpc`
> - Install packages: Use fileserver's Julia depot `~/.julia` (302 packages available)
> - Prepare data: All file operations must go through mack (falcon has 1GB quota limit)
>
> **Step 2: Job Submission (via cluster falcon)**
> - Submit SLURM jobs: `ssh scholten@falcon`, submit from `~/globtim_hpc`
> - Required: `--account=mpi --partition=batch`
> - Jobs access fileserver data via NFS automatically
>
> **Step 3: Results Collection**
> - Monitor: `ssh scholten@falcon 'squeue -u scholten'`
> - Collect: Results in `~/globtim_hpc/results/` (accessible from both mack and falcon)
>
> **âš ï¸ NEVER**: Run jobs from `/tmp`, install packages on falcon, or exceed falcon's 1GB quota

### ğŸš€ Quick Start - HPC Benchmarking

#### Step 1: Prepare Code (Fileserver)
```bash
# Connect to fileserver for code management
ssh scholten@mack
cd ~/globtim_hpc
# Upload code, install packages, prepare data
```

#### Step 2: Submit Jobs (Cluster)
```bash
# Connect to cluster for job submission
ssh scholten@falcon
cd ~/globtim_hpc

# Direct SLURM submission (recommended)
sbatch --account=mpi --partition=batch your_job_script.slurm

# Or use updated Python scripts
python submit_deuflhard_fileserver.py --mode quick
python submit_basic_test_fileserver.py --mode quick
```

#### Step 3: Monitor and Collect
```bash
# Monitor jobs from anywhere
squeue -u scholten

# Results automatically saved to fileserver
ls -la ~/globtim_hpc/results/
```

## ğŸš€ Quick Start - Precision-Aware Optimization

> ğŸ“¦ **Package Dependencies**: For complete information about GlobTim's modern dependency architecture with weak dependencies and extensions, see **[`PACKAGE_DEPENDENCIES.md`](PACKAGE_DEPENDENCIES.md)**

### Basic Usage with Precision Control

```julia
using Globtim, DynamicPolynomials

# Define optimization problem
f = Deuflhard  # Built-in test function
TR = test_input(f, dim=2, center=[0.0, 0.0], sample_range=1.2)

# Create polynomial with AdaptivePrecision (recommended)
pol = Constructor(TR, 8, precision=AdaptivePrecision)
println("L2-norm approximation error: $(pol.nrm)")

# Find critical points
@polyvar x[1:2]
solutions = solve_polynomial_system(x, pol)
df = process_crit_pts(solutions, f, TR)

# Enhanced analysis with sparsification
df_enhanced, df_min = analyze_critical_points(f, df, TR, enable_hessian=true)
println("Found $(nrow(df_min)) unique local minima")
```

### Precision Comparison Example

```julia
# Compare different precision types
precisions = [Float64Precision, AdaptivePrecision, RationalPrecision]
for prec in precisions
    pol = Constructor(TR, 6, precision=prec)
    println("$(prec): L2-norm = $(pol.nrm), type = $(eltype(pol.coeffs))")
end
```

## ğŸ“ Repository Structure

```
globtim/
â”œâ”€â”€ src/                    # Core Globtim source code
â”œâ”€â”€ test/                   # Comprehensive test suite
â”œâ”€â”€ docs/                   # Documentation (organized & consolidated)
â”œâ”€â”€ Examples/               # Usage examples and benchmarks
â”œâ”€â”€ hpc/                    # âœ… HPC Infrastructure (FULLY OPERATIONAL)
â”‚   â”œâ”€â”€ README.md          # Main HPC guide (verified working)
â”‚   â”œâ”€â”€ docs/              # HPC-specific documentation
â”‚   â”‚   â”œâ”€â”€ FILESERVER_INTEGRATION_GUIDE.md   # Production fileserver guide
â”‚   â”‚   â”œâ”€â”€ HPC_STATUS_SUMMARY.md             # Current status (VERIFIED)
â”‚   â”‚   â”œâ”€â”€ TMP_FOLDER_PACKAGE_STRATEGY.md    # Legacy quota workaround (deprecated)
â”‚   â”‚   â””â”€â”€ archive/       # Historical HPC documentation
â”‚   â”œâ”€â”€ jobs/submission/   # âœ… Verified submission scripts (Job 59780294 success)
â”‚   â”‚   â”œâ”€â”€ submit_deuflhard_fileserver.py    # Fileserver-based Deuflhard benchmark
â”‚   â”‚   â”œâ”€â”€ submit_basic_test_fileserver.py   # Fileserver-based basic tests
â”‚   â”‚   â”œâ”€â”€ working_quota_workaround.py       # Legacy (deprecated)
â”‚   â”‚   â””â”€â”€ FILESERVER_MIGRATION_GUIDE.md     # Migration documentation
â”‚   â”œâ”€â”€ monitoring/python/ # âœ… Working Python monitoring tools
â”‚   â””â”€â”€ config/            # Configuration management
â”œâ”€â”€ tools/                  # Development and maintenance tools
â””â”€â”€ environments/          # Dual environment support (local/HPC)
```

## ğŸ¯ HPC Workflow - PRODUCTION READY âœ…

### Step 1: Environment Setup
```bash
# One-time setup: Install dependencies with quota workaround
cd hpc/jobs/submission
python working_quota_workaround.py --install-all
```

### Step 2: Run Benchmarks
```bash
# Standard HPC Deuflhard benchmark
python submit_deuflhard_hpc.py --mode quick --auto-collect

# Fileserver-based Deuflhard benchmark
python submit_deuflhard_fileserver.py --mode quick --auto-collect

# Basic functionality test
python submit_basic_test_fileserver.py --mode quick --auto-collect

# Custom benchmark functions
python submit_globtim_compilation_test.py --mode quick --function [FUNCTION_NAME]
```

### Step 3: Monitor and Collect Results
```bash
# Automated monitoring with result collection
python automated_job_monitor.py --job-id [JOB_ID] --test-id [TEST_ID]

# Results automatically saved in: hpc/jobs/submission/collected_results/
```

## ğŸ”§ Key Technical Solutions

### âœ… Fileserver Integration (PRODUCTION)
- **Architecture**: Three-tier system (Local â†’ Fileserver â†’ HPC Cluster)
- **Storage**: Persistent fileserver storage via NFS
- **Access**: `ssh scholten@mack` for job management
- **Documentation**: `hpc/docs/FILESERVER_INTEGRATION_GUIDE.md`

### âœ… Package Ecosystem (COMPLETE)
- **Location**: Complete Julia ecosystem on fileserver (`~/.julia/`)
- **Count**: 302 packages including all dependencies
- **Access**: Automatic via NFS from cluster nodes
- **Persistence**: Permanent storage, no reinstallation needed

### âœ… SLURM Integration (STANDARD)
- **Job Submission**: Standard `sbatch` workflow from fileserver
- **Script Creation**: Proper SLURM scripts with NFS paths
- **Resource Management**: Full access to all cluster partitions
- **Results**: Persistent storage on fileserver

## ğŸ¯ Key Features

### ğŸ”¢ Advanced Precision Control
Globtim provides flexible precision parameter options for optimal performance vs accuracy trade-offs:

- **Float64Precision**: Standard double precision for fast computation
- **AdaptivePrecision** â­: Hybrid approach using Float64 for evaluation, BigFloat for coefficients (recommended)
- **RationalPrecision**: Exact rational arithmetic for symbolic computation
- **BigFloatPrecision**: Maximum precision for research applications

```julia
# Example: High-accuracy polynomial approximation
pol = Constructor(TR, 8, precision=AdaptivePrecision)

# Integrate with sparsification for complexity reduction
@polyvar x[1:2]
mono_poly = to_exact_monomial_basis(pol, variables=x)
analysis = analyze_coefficient_distribution(mono_poly)
truncated_poly, stats = truncate_polynomial_adaptive(mono_poly, analysis.suggested_thresholds[1])
```

### ğŸ“Š Production Features

- **Automated Job Submission**: Python-based SLURM integration
- **Real-time Monitoring**: 30-second update intervals
- **Automatic Result Collection**: Structured output parsing
- **Error Handling**: Comprehensive error detection and reporting
- **Scalable Architecture**: Supports multiple concurrent benchmarks
- **Documentation**: Complete setup and troubleshooting guides

## ğŸ“š Documentation

### Core Documentation
- **[Getting Started](docs/src/getting_started.md)**: Installation, basic usage, and precision parameters
- **[Precision Parameters](docs/src/precision_parameters.md)**: Comprehensive guide to precision types and performance trade-offs
- **[API Reference](docs/src/api_reference.md)**: Complete function reference with precision options
- **[Examples](docs/src/examples.md)**: Practical usage examples with different precision types

### Package Architecture
- **[Package Dependencies](PACKAGE_DEPENDENCIES.md)**: **ğŸ“¦ COMPLETE DEPENDENCY GUIDE** - Modern weak dependency system, extensions, HPC compatibility

### Development & HPC
- **Main Guide**: `DEVELOPMENT_GUIDE.md` (consolidated setup instructions)
- **HPC Guide**: `hpc/README.md` (cluster-specific documentation)
- **Quota Solution**: `hpc/docs/TMP_FOLDER_PACKAGE_STRATEGY.md`
- **Troubleshooting**: `docs/troubleshooting/` (organized problem solutions)
- **Cleanup Summary**: `DOCUMENTATION_CLEANUP_SUMMARY.md` (recent organization)
